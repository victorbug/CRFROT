{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_505606/3777615979.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!gdown \"1iUNtsGGS2rFgvtGy9wp8H1mnfFh0OmuZ&confirm=t\"#PascalTrainVal_VicgabusaAzure#20230610\n",
    "#!gdown \"15UYA8GQ7D-bS1bxY1_t51GjsUL8yfwo1&confirm=t\"#Embryo_VicgabusaAzure#20230610\n",
    "\n",
    "#!unzip PascalTrainVal.zip\n",
    "#!unzip embryoDataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CLASE DEEPLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 18:34:29.104167: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-08 18:34:29.676141: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/vbugueno/.local/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2024-02-08 18:34:29.676185: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/vbugueno/.local/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2024-02-08 18:34:29.676190: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lst_imagenes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#auxim=cv2.imread(lst_imagenes[1])\n",
    "#print(auxim.shape)\n",
    "#print(np.unique(auxim))\n",
    "#print(type(auxim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA_DIR = \"./COLAB_instance-level-human-parsing2/embrion/secuencia\"\n",
    "#sorted(glob(os.path.join(DATA_DIR, \"raw/*\")))[1:1+10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def myfunc(a,b, *args, **kwargs):\n",
    "#    for ar in args:\n",
    "#        print (ar)\n",
    "#myfunc(1,2,3,4,5,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    listaFiles=sorted(glob(r\"./\"+r\"COLAB_instance-level-human-parsing2/embryoDataset\"+r\"/\"+r\"video_animal2_proyeccion_SeqDA/*\"))\n",
    "    #listaFiles=[x.split(r'')[0] for x in listaFiles]\n",
    "    listaFiles\n",
    "\n",
    "    import re\n",
    "\n",
    "    out=[]\n",
    "    for listaFiles_i in listaFiles:\n",
    "        aux=re.search(r\"[^/]+$\", listaFiles_i)[0]\n",
    "        aux=re.match(r\".*(?=\\.)\",aux)[0]\n",
    "        out.append(aux)\n",
    "\n",
    "    out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    def has_common_string(list1, list2, list3):\n",
    "        set1 = set(list1)\n",
    "        set2 = set(list2)\n",
    "        set3 = set(list3)\n",
    "        common_strings = set1.intersection(set2)\n",
    "        common_strings = common_strings.intersection(set3)\n",
    "        print(\"common_strings: \", common_strings)\n",
    "        return len(common_strings) > 0\n",
    "\n",
    "\n",
    "    list1 = ['kiwi', 'banana', 'orange']\n",
    "    list2 = ['banana', 'grape', 'kiwi']\n",
    "    list3 = ['orange', 'kiwi', 'watermelon']\n",
    "\n",
    "\n",
    "\n",
    "    if has_common_string(list1, list2, list3):\n",
    "        print(\"The three lists have a common string.\")\n",
    "    else:\n",
    "        print(\"The three lists do not have a common string.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class class_DeepLab():\n",
    "    \n",
    "    def __call__(self, \n",
    "                 str_entrenaroCargarIn, \n",
    "                 str_dirModelLoadIn, \n",
    "                 boo_guardarModeloIn, \n",
    "                 int_image_sizeIn, \n",
    "                 int_batch_sizeIn, \n",
    "                 int_num_classesIn, \n",
    "                 str_data_dirIn, \n",
    "                 str_mask_folderIn,\n",
    "                 str_raw_folderIn, \n",
    "                 int_num_train_imagesIn, \n",
    "                 int_num_val_imagesIn, \n",
    "                 int_num_test_imagesIn, \n",
    "                 int_epocasIn,\n",
    "                 boo_activarCRFIn\n",
    "                ):\n",
    "        \"\"\"entrenaroCargar tiene 2 opciones: Train o Load \"\"\"\n",
    "        \n",
    "        self.str_entrenaroCargar=str_entrenaroCargarIn\n",
    "        self.str_dirModelLoad=str_dirModelLoadIn\n",
    "        self.boo_guardarModeloIn=boo_guardarModeloIn\n",
    "        \n",
    "        self.int_IMAGE_SIZE = int_image_sizeIn#Se usa en mode, en deeplabv3+ y read_image\n",
    "        self.int_BATCH_SIZE = int_batch_sizeIn\n",
    "        self.int_NUM_CLASSES = int_num_classesIn\n",
    "        #DATA_DIR = \"./instance-level_human_parsing/instance-level_human_parsing/Training\"\n",
    "        #DATA_DIR = \"./COLAB_instance-level-human-parsing2/instance-level_human_parsing/instance-level_human_parsing/Training\"\n",
    "        str_DATA_DIR = r\"./\"+str_data_dirIn\n",
    "        str_MASK_Folder=str_mask_folderIn+r\"/*\" #EVLstack_SeqDA\n",
    "        str_RAW_Folder=str_raw_folderIn+r\"/*\" #video_animal2_proyeccion_SeqDA2\n",
    "        int_NUM_TRAIN_IMAGES = int_num_train_imagesIn\n",
    "        int_NUM_VAL_IMAGES = int_num_val_imagesIn\n",
    "        #NUM_TEST_IMAGES = 4000\n",
    "        int_NUM_TEST_IMAGES = int_num_test_imagesIn\n",
    "        int_EPOCAS=int_epocasIn\n",
    "        \n",
    "        from datetime import datetime as dt  #20230119_1734\n",
    "        str_fechaInicio=dt.today().strftime('%Y%m%d_%H%M')#20230119_1734\n",
    "            \n",
    "\n",
    "            \n",
    "        \n",
    "        if(self.str_entrenaroCargar!=\"Train\" and self.str_entrenaroCargar!=\"Load\"):#20230619\n",
    "            raise Exception(\"Escojer Train o Load o no tiene sentido correr esta clase\")  \n",
    "            \n",
    "        ####\n",
    "        print(\"deeplab str_data_dirIn: \", str_data_dirIn)\n",
    "        \n",
    "        if(str_data_dirIn==\"PascalTrainVal\"):\n",
    "            str_DatasetNombre = \"DatasetPascal\"\n",
    "        elif(str_data_dirIn==\"COLAB_instance-level-human-parsing2/embryoDataset\"):\n",
    "            str_DatasetNombre = \"DatasetEmbrion\"\n",
    "        elif(str_data_dirIn==\"embryoDataset_SinDA\"):\n",
    "            str_DatasetNombre = \"DatasetEmbrionSinDA\"\n",
    "        elif(str_data_dirIn==r\"2D_Neuronal_dataset_Proc\"):\n",
    "            str_DatasetNombre = \"DatasetNeuron\"\n",
    "        elif(str_data_dirIn==r\"Warwick_QU_Dataset_Released 2016_07_08_Proc\"):\n",
    "            str_DatasetNombre = \"DatasetTissue\"\n",
    "        else:\n",
    "            raise Exception(\"Si str_data_dirIn no es PascalTrainVal ni tampoco COLAB_instance-level-human-parsing2/embryoDataset ni neuron. Tengo que saber si es de pascal para poenrle ignore label en el if\")    \n",
    "        ###\n",
    "        ###\n",
    "        if(self.str_entrenaroCargar==\"Load\"):\n",
    "            if((str_DatasetNombre==\"DatasetPascal\") and \n",
    "               (\"pascal\" not in self.str_dirModelLoad.lower())\n",
    "              ):\n",
    "                raise Exception(\"Ojo parece que se esta cargando un modelo que no se condice con el dataset entrenado, en el nombre deberia salir pascal. El nombre del modelo entrenado no contiene la palabra de del dataset extraida de str_data_dirIn\")    \n",
    "            if((str_DatasetNombre==\"DatasetEmbrion\") and \n",
    "               ((\"embryo\" not in self.str_dirModelLoad.lower()) and\n",
    "                (\"embrion\" not in self.str_dirModelLoad.lower())\n",
    "               )\n",
    "              ):\n",
    "                raise Exception(\"Ojo parece que se esta cargando un modelo que no se condice con el dataset entrenado, en el nombre deberia salir embryo. El nombre del modelo entrenado no contiene la palabra de del dataset extraida de str_data_dirIn\")    \n",
    "            if((str_DatasetNombre==\"embryoDataset_SinDA\") and \n",
    "               (\"embryo\" not in self.str_dirModelLoad.lower())\n",
    "              ):\n",
    "                raise Exception(\"Ojo parece que se esta cargando un modelo que no se condice con el dataset entrenado, en el nombre deberia salir embryo. El nombre del modelo entrenado no contiene la palabra de del dataset extraida de str_data_dirIn\")    \n",
    "            \n",
    "        \n",
    "        if (str_DatasetNombre == \"DatasetPascal\"):\n",
    "            \n",
    "            ####\n",
    "            lst_train_masks = sorted(glob(os.path.join(str_DATA_DIR, str_MASK_Folder)))[1:1+int_NUM_TRAIN_IMAGES]\n",
    "            lst_train_raws = sorted(glob(os.path.join(str_DATA_DIR, str_RAW_Folder)))[1:1+int_NUM_TRAIN_IMAGES]#20230123_1544\n",
    "            \n",
    "            ####\n",
    "            lst_val_masks = sorted(glob(os.path.join(str_DATA_DIR, str_MASK_Folder)))[\n",
    "              1+int_NUM_TRAIN_IMAGES : 1+ int_NUM_TRAIN_IMAGES+ int_NUM_VAL_IMAGES\n",
    "            ]\n",
    "            lst_val_raws = sorted(glob(os.path.join(str_DATA_DIR, str_RAW_Folder)))[#20230123_1544\n",
    "              1+int_NUM_TRAIN_IMAGES : 1+ int_NUM_TRAIN_IMAGES+ int_NUM_VAL_IMAGES#20230123_1544\n",
    "            ]#20230123_1544\n",
    "            \n",
    "            ####\n",
    "            lst_test_masks = sorted(glob(os.path.join(str_DATA_DIR, str_MASK_Folder)))[\n",
    "              1+ int_NUM_TRAIN_IMAGES+ int_NUM_VAL_IMAGES : 1+ int_NUM_TRAIN_IMAGES+ int_NUM_VAL_IMAGES + int_NUM_TEST_IMAGES\n",
    "            ]\n",
    "            lst_test_raws = sorted(glob(os.path.join(str_DATA_DIR, str_RAW_Folder)))[#20230123_1544\n",
    "              1+ int_NUM_TRAIN_IMAGES+ int_NUM_VAL_IMAGES : 1+ int_NUM_TRAIN_IMAGES+ int_NUM_VAL_IMAGES + int_NUM_TEST_IMAGES#20230123_1544\n",
    "            ]#20230123_1544\n",
    "        \n",
    "            lst_train_images, lst_val_images, lst_test_images = lst_train_raws, lst_val_raws, lst_test_raws\n",
    "\n",
    "        \n",
    "        \n",
    "        if(str_DatasetNombre == \"DatasetEmbrion\"):#Esto es para sacar a los data augmented de test y validation\n",
    "            if (int_num_train_imagesIn+int_num_val_imagesIn+int_num_test_imagesIn>145):\n",
    "                raise Exception(\"Hay solo 145 imagenes, hay que achicar int_testFilescount o int_validationFilescount o int_trainingFilescount\")\n",
    "                \n",
    "        if(str_DatasetNombre == \"DatasetNeuron\"):#Esto es para sacar a los data augmented de test y validation\n",
    "            if (int_num_train_imagesIn+int_num_val_imagesIn+int_num_test_imagesIn>210):\n",
    "                raise Exception(\"Hay solo 210 imagenes, hay que achicar int_testFilescount o int_validationFilescount o int_trainingFilescount\")\n",
    "        \n",
    "        if(str_DatasetNombre == \"DatasetTissue\"):#Esto es para sacar a los data augmented de test y validation\n",
    "            if (int_num_train_imagesIn+int_num_val_imagesIn+int_num_test_imagesIn>165):\n",
    "                raise Exception(\"Hay solo 165 imagenes, hay que achicar int_testFilescount o int_validationFilescount o int_trainingFilescount\")\n",
    "        \n",
    "        \n",
    "        if(str_DatasetNombre == \"DatasetEmbrion\" or str_DatasetNombre == \"DatasetNeuron\" or str_DatasetNombre == \"DatasetTissue\"):#Esto es para sacar a los data augmented de test y validation\n",
    "            #str_mask_folder = r\"COLAB_instance-level-human-parsing2/embryoDataset/EVLstack_SeqDA\"\n",
    "            #str_raw_folder = r\"COLAB_instance-level-human-parsing2/embryoDataset/video_animal2_proyeccion_SeqDA2\"\n",
    "            #str_mask_folder = r\"COLAB_instance-level-human-parsing2/embryoDataset/EVLstack_SeqDA\"\n",
    "            #str_raw_folder = r\"COLAB_instance-level-human-parsing2/embryoDataset/video_animal2_proyeccion_SeqDA2\"\n",
    "            str_mask_folder= os.path.join(str_DATA_DIR, str_mask_folderIn)\n",
    "            str_raw_folder= os.path.join(str_DATA_DIR, str_raw_folderIn)\n",
    "            \n",
    "            #print(\"str_mask_folder: \", str_mask_folder)\n",
    "            #print(\"str_raw_folder: \", str_raw_folder)\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "            #seed = 123 \n",
    "            #import random\n",
    "            #random.seed(seed)\n",
    "            \n",
    "            \n",
    "            lst_str_filenamePath_10R_Masks = glob(os.path.join(str_mask_folder, \"1OR*\"))#1 (para que quede al principio) y OR de original\n",
    "            lst_str_filenamePath_10R_Raws = glob(os.path.join(str_raw_folder, \"1OR*\"))#Parece que no se usa\n",
    "\n",
    "            lst_str_filenamePath_Masks = glob(str_mask_folder + '/*')\n",
    "            lst_str_filenamePath_Raws = glob(str_raw_folder + '/*')\n",
    "            \n",
    "            \n",
    "            #print(r\"lst_str_filenamePath_10R_Masks: \", os.path.join(str_mask_folder, \"1OR*\"))\n",
    "            #print(r\"lst_str_filenamePath_Masks: \", str_mask_folder + '/*')\n",
    "            \n",
    "            #for lst_str_filenamePath_Masks_i in lst_str_filenamePath_Masks:\n",
    "            #    print(\"lst_str_filenamePath_Masks_i: \", lst_str_filenamePath_Masks_i)\n",
    "            \n",
    "            #for lst_str_filenamePath_10R_Masks_i in lst_str_filenamePath_10R_Masks:\n",
    "            #    print(\"lst_str_filenamePath_10R_Masks_i: \", lst_str_filenamePath_10R_Masks_i)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            #Test\n",
    "            #import random\n",
    "            #random.seed(11)\n",
    "            #np.random.seed(11)\n",
    "            #gen = np.random.default_rng()\n",
    "            \n",
    "            #lst_str_filenamePath_10R_testSet = random.sample(set(lst_str_filenamePath_10R_Masks), int_num_test_imagesIn)#Selecciono solo de entre 1OR que es la imagen sin ninguna rotacion\n",
    "            #int_seed=1\n",
    "            #np.random.seed(int_seed)\n",
    "            \n",
    "            import random\n",
    "\n",
    "            #lower = 1\n",
    "            #upper = 10\n",
    "            int_seed = random.randint(1, 10000)#Redflag. QUEDA DETERMINISTICO SI ESTO SE DEJA FIJO\n",
    "            int_seed = 3873#Redflag. QUEDA DETERMINISTICO SI ESTO SE DEJA FIJO\n",
    "            np.random.seed(int_seed)\n",
    "            #print(random_int)\n",
    "            \n",
    "            \n",
    "            \n",
    "            if False:\n",
    "                my_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "                sample = np.random.choice(my_list, size=3, replace=False)\n",
    "                print(\"sample: \", sample)\n",
    "                my_list = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\"]\n",
    "                sample = np.random.choice(my_list, size=3, replace=False)\n",
    "                print(\"sample: \", sample)\n",
    "                #print(\"list(set(lst_str_filenamePath_10R_Masks))\", list(set(lst_str_filenamePath_10R_Masks)))\n",
    "                print(\"int_num_test_imagesIn\", int_num_test_imagesIn)\n",
    "\n",
    "            \n",
    "            #Test\n",
    "            lst_str_filenamePath_10R_testSet = np.random.choice(lst_str_filenamePath_10R_Masks, int_num_test_imagesIn, replace=False)#Selecciono solo de entre 1OR que es la imagen sin ninguna rotacion\n",
    "            lst_str_filenamePath_10R_testSet = sorted(lst_str_filenamePath_10R_testSet)\n",
    "            \n",
    "            \n",
    "            #np.random.choice(my_list, size=3, replace=False)\n",
    "            #lst_str_filenamePath_10R_testSet = random.sample(set(lst_str_filenamePath_10R_Masks), int_num_test_imagesIn)#Selecciono solo de entre 1OR que es la imagen sin ninguna rotacion\n",
    "            #lst_str_filenamePath_10R_testSet = gen.choice(list(set(lst_str_filenamePath_10R_Masks)), int_num_test_imagesIn, replace=False)\n",
    "            \n",
    "            #my_array = np.array(set(lst_str_filenamePath_10R_Masks))\n",
    "            #lst_str_filenamePath_10R_testSet = np.random.choice(my_array, int_num_test_imagesIn, replace=False).tolist()#Selecciono solo de entre 1OR que es la imagen sin ninguna rotacion\n",
    "            #lst_str_filename_10R_testSet = [os.path.splitext(os.path.basename(path))[0] for path in lst_str_filenamePath_10R_testSet]#Me quedo con los filenames. Ejemplo: 1OR0027\n",
    "            #lst_str_filenamePath_10R_testSet_Masks = [path for path in lst_str_filenamePath_Masks if os.path.splitext(os.path.basename(path))[0] in lst_str_filename_10R_testSet]#Recupero el path a partir de los filenames para Mask\n",
    "            #lst_str_filenamePath_10R_testSet_Raws = [path for path in lst_str_filenamePath_Raws if os.path.splitext(os.path.basename(path))[0] in lst_str_filename_10R_testSet]#Recupero el path a partir de los filenames para Raws\n",
    "            lst_str_filename_10R_testSet = [os.path.splitext(file)[0][-4:]  for file in lst_str_filenamePath_10R_testSet] # Me quedo solo con el nombre del archivo sin prefijos ni sufijos y con extensión\n",
    "            lst_str_filenamePath_testSet_Masks = [file_path for file_path in lst_str_filenamePath_Masks if any(substr in file_path for substr in lst_str_filename_10R_testSet)]\n",
    "            lst_str_filenamePath_testSet_Raws = [file_path for file_path in lst_str_filenamePath_Raws if any(substr in file_path for substr in lst_str_filename_10R_testSet)]\n",
    "\n",
    "            \n",
    "            #Validation\n",
    "            set_aux_validationSet= [x for x in lst_str_filenamePath_10R_Masks if x not in lst_str_filenamePath_10R_testSet]\n",
    "            #lst_str_filenamePath_10R_validationSet = random.sample(set(lst_str_filenamePath_10R_Masks)-set(lst_str_filenamePath_10R_testSet), int_num_val_imagesIn)#Selecciono solo de entre 1OR que es la imagen sin ninguna rotacion\n",
    "            lst_str_filenamePath_10R_validationSet = np.random.choice(set_aux_validationSet, int_num_val_imagesIn, replace=False)#Selecciono solo de entre 1OR que es la imagen sin ninguna rotacion\n",
    "            lst_str_filenamePath_10R_validationSet = sorted(lst_str_filenamePath_10R_validationSet)\n",
    "\n",
    "            \n",
    "            #my_array = np.array(set(lst_str_filenamePath_10R_Masks)-set(lst_str_filenamePath_10R_testSet))\n",
    "            #lst_str_filenamePath_10R_validationSet = np.random.choice(set(lst_str_filenamePath_10R_Masks)-set(lst_str_filenamePath_10R_testSet), int_num_val_imagesIn, replace=False)#Selecciono solo de entre 1OR que es la imagen sin ninguna rotacion\n",
    "            #lst_str_filename_10R_validationSet = [os.path.splitext(os.path.basename(path))[0] for path in lst_str_filenamePath_10R_validationSet]#Me quedo con los filenames    \n",
    "            #lst_str_filenamePath_10R_validationSet_Masks = [path for path in lst_str_filenamePath_Masks if os.path.splitext(os.path.basename(path))[0] in lst_str_filename_10R_validationSet]\n",
    "            #lst_str_filenamePath_10R_validationSet_Raws = [path for path in lst_str_filenamePath_Raws if os.path.splitext(os.path.basename(path))[0] in lst_str_filename_10R_validationSet]\n",
    "            lst_str_filename_10R_validationSet = [os.path.splitext(file)[0][-4:]  for file in lst_str_filenamePath_10R_validationSet] # Me quedo solo con el nombre del archivo sin prefijos ni sufijos y con extensión\n",
    "            lst_str_filenamePath_validationSet_Masks = [file_path for file_path in lst_str_filenamePath_Masks if any(substr in file_path for substr in lst_str_filename_10R_validationSet)]\n",
    "            lst_str_filenamePath_validationSet_Raws = [file_path for file_path in lst_str_filenamePath_Raws if any(substr in file_path for substr in lst_str_filename_10R_validationSet)]\n",
    "\n",
    "            \n",
    "            #Training\n",
    "            set_aux_trainingSet= [x for x in lst_str_filenamePath_10R_Masks if x not in set_aux_validationSet]\n",
    "            #lst_str_filenamePath_10R_trainingSet = random.sample(set(lst_str_filenamePath_10R_Masks)-set(lst_str_filenamePath_10R_testSet)-set(lst_str_filenamePath_10R_validationSet), int_num_train_imagesIn) #Selecciono solo de entre 1OR que es la imagen sin ninguna rotacion\n",
    "            lst_str_filenamePath_10R_trainingSet = np.random.choice(list(set(lst_str_filenamePath_10R_Masks)-set(lst_str_filenamePath_10R_testSet)-set(lst_str_filenamePath_10R_validationSet)), int_num_train_imagesIn, replace=False) #Selecciono solo de entre 1OR que es la imagen sin ninguna rotacion\n",
    "            lst_str_filenamePath_10R_trainingSet = sorted(lst_str_filenamePath_10R_trainingSet)\n",
    "\n",
    "            \n",
    "            #lst_str_filenamePath_10R_trainingSet = np.random.choice(set(lst_str_filenamePath_10R_Masks)-set(lst_str_filenamePath_10R_testSet)-set(lst_str_filenamePath_10R_validationSet), int_num_train_imagesIn, replace=False) #Selecciono solo de entre 1OR que es la imagen sin ninguna rotacion\n",
    "            lst_str_filename_10R_trainingSet = [os.path.splitext(file)[0][-4:]  for file in lst_str_filenamePath_10R_trainingSet] # Me quedo solo con el nombre del archivo sin prefijos ni sufijos y con extensión\n",
    "            lst_str_filenamePath_trainingSet_Masks = [file_path for file_path in lst_str_filenamePath_Masks if any(substr in file_path for substr in lst_str_filename_10R_trainingSet)]\n",
    "            lst_str_filenamePath_trainingSet_Raws = [file_path for file_path in lst_str_filenamePath_Raws if any(substr in file_path for substr in lst_str_filename_10R_trainingSet)]\n",
    "\n",
    "            if True:\n",
    "                print(\"lst_str_filenamePath_10R_testSet: \")\n",
    "                for lst_str_filenamePath_10R_testSet_i in lst_str_filenamePath_10R_testSet:\n",
    "                    print(lst_str_filenamePath_10R_testSet_i)\n",
    "                print(\"lst_str_filenamePath_10R_validationSet: \")\n",
    "                for lst_str_filenamePath_10R_validationSet_i in lst_str_filenamePath_10R_validationSet:\n",
    "                    print(lst_str_filenamePath_10R_validationSet_i)\n",
    "\n",
    "                print(\"lst_str_filenamePath_10R_trainingSet: \")\n",
    "                for lst_str_filenamePath_10R_trainingSet_i in lst_str_filenamePath_10R_trainingSet:\n",
    "                    print(lst_str_filenamePath_10R_trainingSet_i)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            #lst_test_masks=lst_str_filenamePath_10R_testSet_Masks\n",
    "            #lst_test_images=lst_str_filenamePath_10R_testSet_Raws\n",
    "            \n",
    "            #lst_val_masks=lst_str_filenamePath_10R_validationSet_Masks\n",
    "            #lst_val_images=lst_str_filenamePath_10R_validationSet_Raws\n",
    "            \n",
    "            lst_test_masks=sorted(lst_str_filenamePath_testSet_Masks)\n",
    "            lst_test_images=sorted(lst_str_filenamePath_testSet_Raws)\n",
    "            \n",
    "            lst_val_masks=sorted(lst_str_filenamePath_validationSet_Masks)\n",
    "            lst_val_images=sorted(lst_str_filenamePath_validationSet_Raws)\n",
    "            \n",
    "            \n",
    "            lst_train_masks=sorted(lst_str_filenamePath_trainingSet_Masks)\n",
    "            lst_train_images=sorted(lst_str_filenamePath_trainingSet_Raws)\n",
    "  \n",
    "        \n",
    "        \n",
    "        if False:\n",
    "            int_ultimaImagen = int_NUM_TRAIN_IMAGES+ int_NUM_VAL_IMAGES + int_NUM_TEST_IMAGES\n",
    "            #test_images0 = [sorted(glob(os.path.join(DATA_DIR, r\"video_animal2_proyeccion_SeqDA/*\")))[0]]\n",
    "            #test_images0 = [sorted(glob(os.path.join(DATA_DIR, r\"video_animal2_proyeccion_SeqDA/*\")))[ultimaImagen]]\n",
    "            test_images0 = [sorted(glob(os.path.join(str_DATA_DIR, str_RAW_Folder)))[int_ultimaImagen]]#20230123_1544\n",
    "            #test_masks0 = [sorted(glob(os.path.join(DATA_DIR, r\"EVLstack_SeqDA/*\")))[0]]\n",
    "            test_masks0 = [sorted(glob(os.path.join(str_DATA_DIR, str_MASK_Folder)))[int_ultimaImagen]]\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        if (\"Si estoy tirando cientos de casos, es mejor dejarlas en false porque printean mucho\"!=\"Si estoy tirando cientos de casos, es mejor dejarlas en false porque printean mucho\"):\n",
    "            print(\"\\x1b[34m\\\"A20220911_DeeplabVBS. Printear Imagenes originales que entrenaron, validaron y testearon modelo\\\"\\x1b[0m\")\n",
    "            print(\"len(lst_train_masks): \", len(lst_train_masks))\n",
    "            print(\"len(lst_val_masks): \", len(lst_val_masks))\n",
    "            print(\"len(lst_test_masks): \", len(lst_test_masks))\n",
    "            \n",
    "            \n",
    "            print(\"train_images: \")\n",
    "            for lst_train_images_i in lst_train_images:\n",
    "                print(lst_train_images_i)\n",
    "            print(\"val_images: \")\n",
    "            for lst_val_images_i in lst_val_images:\n",
    "                print(lst_val_images_i)\n",
    "            print(\"test_images: \")\n",
    "            for lst_test_images_i in lst_test_images:\n",
    "                print(lst_test_images_i)\n",
    "\n",
    "        \n",
    "        \n",
    "        train_dataset = self.data_generator(lst_train_images, lst_train_masks)\n",
    "        val_dataset = self.data_generator(lst_val_images, lst_val_masks)\n",
    "        test_dataset = self.data_generator(lst_test_images, lst_test_masks)\n",
    "\n",
    "        print(\"\\x1b[34m\\\"Printear Datasets\\\"\\x1b[0m\")\n",
    "        print(\"Train Dataset:\", train_dataset)\n",
    "        print(\"Val Dataset:\", val_dataset)\n",
    "        print(\"Test Dataset:\", test_dataset)\n",
    "\n",
    "        print(\"len(train_images)\",len(lst_train_images))\n",
    "        print(\"len(val_images)\",len(lst_val_images))\n",
    "        print(\"len(test_images)\",len(lst_test_images))\n",
    "        \n",
    "        #print(\"main self.int_IMAGE_SIZE\", self.int_IMAGE_SIZE)\n",
    "        self.model = self.DeeplabV3Plus(image_size=self.int_IMAGE_SIZE, num_classes=self.int_NUM_CLASSES)\n",
    "        #self.model.summary()\n",
    "        \n",
    "        tf.keras.utils.plot_model(self.model, show_shapes=True)\n",
    "        \n",
    "        \n",
    "        #loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        #loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)#, ignore_class=255)#20230127_0850 , ignore_class=21\n",
    "        if(str_DatasetNombre==\"DatasetPascal\"):\n",
    "            loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False,ignore_class=21)#, ignore_class=255)#20230127_0850 ,ignore_class=21\n",
    "        elif(str_DatasetNombre==\"DatasetEmbrion\"):\n",
    "            loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False,ignore_class=None)#, ignore_class=255)#20230127_0850 ,ignore_class=21\n",
    "        elif(str_DatasetNombre==\"DatasetNeuron\"):\n",
    "            loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False,ignore_class=None)#, ignore_class=255)#20230127_0850 ,ignore_class=21\n",
    "        elif(str_DatasetNombre==\"DatasetEmbrionSinDA\"):\n",
    "            loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False,ignore_class=None)#, ignore_class=255)#20230127_0850 ,ignore_class=21\n",
    "        elif(str_DatasetNombre==\"DatasetTissue\"):\n",
    "            loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False,ignore_class=None)#, ignore_class=255)#20230127_0850 ,ignore_class=21\n",
    "        \n",
    "        \n",
    "        else:\n",
    "            raise Exception(\"Si str_data_dirIn no es PascalTrainVal ni tampoco COLAB_instance-level-human-parsing2/embryoDataset. Tengo que saber si es de pascal para poenrle ignore label en el if\")\n",
    "            \n",
    "        \n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "        \n",
    "        self.model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "        loss=loss,\n",
    "        metrics=[\"accuracy\"],\n",
    "        )\n",
    "\n",
    "        \n",
    "        if True: #Mostrar train 20230707. QUE NO SE TRASLAPEN LOS GRUPOS\n",
    "            if False:\n",
    "                print(\"Antes de entrar al entrenamiento\")\n",
    "                for lst_train_images_i, lst_train_masks_i in zip(lst_train_images, lst_train_masks):\n",
    "                    print(r\"lst_train_images_i: \", lst_train_images_i)\n",
    "                    print(r\"lst_train_masks_i: \", lst_train_masks_i)\n",
    "                \n",
    "                \n",
    "            set_lst_train_images = set(lst_train_images)\n",
    "            set_lst_val_images = set(lst_val_images)\n",
    "            set_lst_test_images = set(lst_test_images)\n",
    "     \n",
    "           \n",
    "            set_common_strings1 = set_lst_train_images.intersection(set_lst_val_images)\n",
    "            set_common_strings2 = set_lst_train_images.intersection(set_lst_test_images)\n",
    "            set_common_strings3 = set_lst_val_images.intersection(set_lst_test_images)\n",
    "\n",
    "            print(\"set_common_strings1 Train Val: \", set_common_strings1)\n",
    "            print(\"set_common_strings2 Train Test: \", set_common_strings2)\n",
    "            print(\"set_common_strings3 Val Test: \", set_common_strings3)\n",
    "            \n",
    "            if((len(set_common_strings1)>0) or (len(set_common_strings2)>0) or (len(set_common_strings3)>0)):\n",
    "                raise Exception(\"Se traslapan los conjuntos de training, validacion y testeo!\")    \n",
    "\n",
    "\n",
    "\n",
    "        if(self.str_entrenaroCargar==\"Train\"):#20230119_1734\n",
    "            print(\"SE METIO A TRAIN\")            \n",
    "            \n",
    "                  \n",
    "            import time#202306100922\n",
    "            flo_start_time = time.time()#202306100922            \n",
    "            history = self.model.fit(train_dataset, validation_data=val_dataset, epochs=int_EPOCAS, callbacks=[callback])#original son 25 epochs\n",
    "            flo_end_time = time.time()#202306100922\n",
    "            \n",
    "            plt.plot(history.history[\"loss\"])\n",
    "            plt.title(\"Training Loss\")\n",
    "            plt.ylabel(\"loss\")\n",
    "            plt.xlabel(\"epoch\")\n",
    "            plt.show()\n",
    "\n",
    "            plt.plot(history.history[\"accuracy\"])\n",
    "            plt.title(\"Training Accuracy\")\n",
    "            plt.ylabel(\"accuracy\")\n",
    "            plt.xlabel(\"epoch\")\n",
    "            plt.show()\n",
    "\n",
    "            plt.plot(history.history[\"val_loss\"])\n",
    "            plt.title(\"Validation Loss\")\n",
    "            plt.ylabel(\"val_loss\")\n",
    "            plt.xlabel(\"epoch\")\n",
    "            plt.show()\n",
    "\n",
    "            plt.plot(history.history[\"val_accuracy\"])\n",
    "            plt.title(\"Validation Accuracy\")\n",
    "            plt.ylabel(\"val_accuracy\")\n",
    "            plt.xlabel(\"epoch\")\n",
    "            plt.show()\n",
    "            \n",
    "            int_num_epochs = len(history.epoch)#20230610\n",
    "            print(\"Epochs used: \",int_num_epochs)#20230610\n",
    "            \n",
    "            if False:#20230613\n",
    "                if(self.boo_guardarModeloIn==True):#20230119_1734\n",
    "                    str_carpetaDir = str_data_dirIn.rsplit('/', 1)[-1]\n",
    "                    from datetime import datetime as dt  #20230119_1734\n",
    "                    str_fecha=dt.today().strftime('%Y%m%d_%H%M')#20230119_1734\n",
    "                    str_prefijoModel=str_carpetaDir+\"B\"+str(int_batch_sizeIn)+\"NC\"+str(int_num_classesIn)+\"Tra\"+str(int_num_train_imagesIn)+\"Val\"+str(int_num_val_imagesIn)+\"Tes\"+str(int_num_test_imagesIn)+\"Epo\"+str(int_epocasIn)#20230119_1734\n",
    "                    str_nombreSavedModel=r'saved_models/'+str_fecha+\"_A20220911_class_DeepLabVBS_\"+str_prefijoModel\n",
    "                    #print(r\"Guardando modelo en: \", r'saved_models/'+str_fecha+\"class_DeepLab\"+str_prefijoModel)\n",
    "                    print(r\"Guardando modelo en: \", str_nombreSavedModel)\n",
    "                    #self.model.save(r'saved_models/'+str_fecha+\"_A20220911_class_DeepLabVBS\"+str_prefijoModel)#20230119_1734\n",
    "                    self.model.save(str_nombreSavedModel)#20230119_1734\n",
    "                       \n",
    "        \n",
    "        \n",
    "        \n",
    "        if(self.str_entrenaroCargar==\"Load\"): #20230119_1734    \n",
    "            print(\"SE METIO A LOAD\")\n",
    "            print(\"Modelo a cargar: \", self.str_dirModelLoad)\n",
    "            self.model=tf.keras.models.load_model(r\"saved_models/\"+self.str_dirModelLoad) #20230119_1734\n",
    "            print(\"Modelo cargado\")\n",
    "            #return(self.model)#esperimental... deberia saltarse todo lo siguiente\n",
    "            \n",
    "        \n",
    "        colormap = loadmat(\n",
    "        r\"human_colormap.mat\"\n",
    "        )[\"colormap\"]\n",
    "        colormap = colormap * 100\n",
    "        colormap = colormap.astype(np.uint8)\n",
    "        \n",
    "        #self.plot_predictions(test_images[:4], colormap, model=self.model)\n",
    "        #print(\"Plotear test images\")\n",
    "        \n",
    "        if (True==False):\n",
    "            print(\"\\x1b[34m\\\"Plotear test images\\\"\\x1b[0m\")\n",
    "            self.plot_predictions(lst_test_images, colormap, model=self.model)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        #CALCULAR MIOU INDIVIDUAL  \n",
    "        if(\"CalcularMioUIndividual\"==\"CalcularMioUIndividual\"):\n",
    "            \n",
    "            print(\"\\x1b[34m\\\"ClassDeeplab: CalcularMioUIndividual\\\"\\x1b[0m\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            self.test_masksIM = self.load_dataVBS(lst_test_masks, \n",
    "                                                  mask=True, \n",
    "                                                  to_tensor=False, \n",
    "                                                  img_Size1=self.int_IMAGE_SIZE)\n",
    "            self.test_imagesIM = self.load_dataVBS(lst_test_images, \n",
    "                                                   mask=False, \n",
    "                                                   to_tensor=False, \n",
    "                                                   img_Size1=self.int_IMAGE_SIZE)\n",
    "            \n",
    "            print(\"Marcador1\")\n",
    "            self.lst_predsConArgmax=self.calc_predictionsVBSConArgmax(lst_test_images, \n",
    "                                                                      self.model, \n",
    "                                                                      img_Size2=self.int_IMAGE_SIZE)  \n",
    "            \n",
    "            \n",
    "            print(\"Marcador2\")\n",
    "            self.lst_predsSinArgmax=self.calc_predictionsVBSSinArgmax(lst_test_images, \n",
    "                                                                      self.model, \n",
    "                                                                      img_Size2=self.int_IMAGE_SIZE)\n",
    "            print(\"Marcador3\")\n",
    "            \n",
    "\n",
    "            print(\"boo_activarCRFIn: \", boo_activarCRFIn)\n",
    "            if (boo_activarCRFIn==True):#20230629\n",
    "                print(\"ENTRO AL IF DEL CRF\")\n",
    "                print(\"ENTRO AL IF DEL CRF\")\n",
    "                print(\"ENTRO AL IF DEL CRF\")\n",
    "                raise Exception(\"Echate este error es que no quiero que tire crf en DEEPLAB, quiero estar seguro\")  \n",
    "                \n",
    "                import import_ipynb\n",
    "                from A20230112_CRF import class_CRF\n",
    "                \n",
    "                lst_predsConArgmaxCRF=[]\n",
    "                for lst_predsSinArgmax_i, lst_test_images_i in zip(self.lst_predsSinArgmax, lst_test_images):\n",
    "                    lst_predsSinArgmax_i=np.squeeze(lst_predsSinArgmax_i)\n",
    "                    \n",
    "                    nda_3DXX3_imgRGB = cv2.cvtColor(cv2.imread(lst_test_images_i), cv2.COLOR_BGR2RGB)##Asi esta en A20221210_pipeline5clase. LE estoy pasando al metodo CRF, con metodo CRF no he cargado las imagenes Raw con tensorflow, solo con cv2. Para deeplab si que frecuentemente se leen las imagenes con tensorflow y no con cv2\n",
    "                    #print(\"ZZ1\")\n",
    "                    #print(\"nda_3DXX3_imgRGB.shape:\", nda_3DXX3_imgRGB.shape)\n",
    "                    #print(\"lst_predsSinArgmax_i.shape:\", lst_predsSinArgmax_i.shape)\n",
    "                    nda_3DXX3_imgRGB = cv2.resize(nda_3DXX3_imgRGB, (lst_predsSinArgmax_i.shape[0], lst_predsSinArgmax_i.shape[1]))#lst_predsSinArgmax8 tiene dimensiones anchox alto x numero de clases\n",
    "                    #print(\"ZZ2\")\n",
    "                    #print(\"nda_3DXX3_imgRGB.shape:\", nda_3DXX3_imgRGB.shape)\n",
    "                    #print(\"lst_predsSinArgmax_i.shape:\", lst_predsSinArgmax_i.shape)\n",
    "                \n",
    "                    \n",
    "                    nda_3DXX2_ProbCRFmap = class_CRF().func_aplicar_CRF(nda_2DXX_sdXIn=-1,#Siempre debe ponerse 0 aqui porque es el metodo original...  El original no tiene estos parametros que hipoteticamente es lo mismo que dejarlos en 0\n",
    "                                                                        nda_2DXX_sdYIn=-1,#Siempre debe ponerse 0 aqui porque es el metodo original... El original no tiene estos parametros que hipoteticamente es lo mismo que dejarlos en 0\n",
    "                                                                        nda_3DXX2_probmapIn=lst_predsSinArgmax_i, \n",
    "                                                                        tpl_ParametroXYIn=(1,1),#20230607tpl_ParametroXYIn1, \n",
    "                                                                        #tpl_ParametroRGBIn=tpl_ParametroRGBIn1, \n",
    "                                                                        #tpl_ParametroXYIn=self.tpl_ParametroXYInFORZADO, #REDFLAG\n",
    "                                                                        tpl_ParametroRGBIn=(1,1,1), \n",
    "                                                                        nda_3DXX3_imgRawIn=nda_3DXX3_imgRGB, \n",
    "                                                                        int_inferenceIn=7, \n",
    "                                                                        int_pairwisebilateralCompatIn=3,\n",
    "                                                                        str_PairwiseoKernel=\"GaussianoSmoothnessKernelYBilateraloAppearanceKernel\"\n",
    "                                                                       )\n",
    "                    nda_2DXX_ProbCRFmap_Argmax = np.argmax(nda_3DXX2_ProbCRFmap, axis=2)\n",
    "                    lst_predsConArgmaxCRF.append(nda_2DXX_ProbCRFmap_Argmax)\n",
    "                self.lst_predsConArgmax=lst_predsConArgmaxCRF.copy()\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            #Aqui calcula el miou\n",
    "            i=0\n",
    "            self.lst_miouIND=[]\n",
    "            for lst_preds_i in self.lst_predsConArgmax:  \n",
    "                mi = tf.keras.metrics.MeanIoU(num_classes=int_num_classesIn)\n",
    "                mi.update_state(self.test_masksIM[i], self.lst_predsConArgmax[i]) #True, pred\n",
    "                aux_mi = (mi.result().numpy())\n",
    "\n",
    "                self.lst_miouIND.append(aux_mi)\n",
    "                i+=1\n",
    "\n",
    "            dict_miouIND = {lst_test_images[i]: self.lst_miouIND[i] for i in range(len(lst_test_images))}\n",
    "\n",
    "\n",
    "            # Printing resultant dictionary\n",
    "\n",
    "\n",
    "            self.miouINDavg = sum(self.lst_miouIND) / len(self.lst_miouIND)    \n",
    "            \n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "            print(\"type(self.test_masksIM[0]: \", type(self.test_masksIM[0]))\n",
    "            print(\"(self.test_masksIM[0]).shape: \", (self.test_masksIM[0]).shape)\n",
    "            print(\"type(self.lst_predsConArgmax [0]: \", type(self.lst_predsConArgmax[0]))\n",
    "            print(\"(self.lst_predsConArgmax[0]).shape \", (self.lst_predsConArgmax[0]).shape)\n",
    "\n",
    "            print(\"\\x1b[31m\\\"Class Deeplab: MIoU todo el data test individual \\\"\\x1b[0m\")\n",
    "            #print(\"self.lst_miouIND (individual): \",self.lst_miouIND)\n",
    "            print(\"len(self.lst_miouIND) (individual): \",len(self.lst_miouIND))\n",
    "            #print(\"avg(iou) (individual): \", sum(self.lst_miou) / len(self.lst_miou))\n",
    "            print(\"self.miouINDavg: \", self.miouINDavg)      \n",
    "            #print(\"dict_miouIND: \", dict_miouIND)\n",
    "            \n",
    "            print(\"dict_miouIND: \")\n",
    "            for item in dict_miouIND.items():\n",
    "                print(item)\n",
    "\n",
    "        \n",
    "        \n",
    "        if(\"CalcularMioUIndividualConLibreria\"==\"CalcularMioUIndividualConLibreria\"):\n",
    "            \n",
    "            print(\"\\x1b[34m\\\"ClassDeeplab: CalcularMioUIndividualConLibreria\\\"\\x1b[0m\")\n",
    "            import import_ipynb\n",
    "            from A20230105_MaskImageModel2mIoU import class_MaskImageModel2mIoU\n",
    "            #i=0 20230613\n",
    "            self.lst_miouINDconLib1=[]\n",
    "            #self.lst_miouINDconLib2=[]\n",
    "            #self.lst_miouINDconLib3=[]\n",
    "            #self.lst_miouINDconLib4=[]#20230119_14:58\n",
    "            self.lst_miouINDconLib5=[]\n",
    "            #self.lst_miouINDconLib6=[] #20230121_1436\n",
    "            self.lst_miouINDconLib7=[] #20230121_1436\n",
    "            #self.lst_miouINDconLib8=[] #20230121_1436\n",
    "            \n",
    "            if(str_DatasetNombre==\"DatasetPascal\"):\n",
    "                self.lst_miouINDconLib7_IL=[] #202300613 IGNORELABEL\n",
    "            \n",
    "            \n",
    "            #listaFiles=os.listdir(r\"./\"+data_dirIn+r\"/\"+r\"EVLstack_SeqDA\"+r\"/\")\n",
    "            #listaFiles=[x.split('.')[0] for x in listaFiles]\n",
    "            #print(\"listaFiles: \",listaFiles)\n",
    "\n",
    "            \n",
    "            \n",
    "            #dir=(sorted(glob(os.path.join(DATA_DIR, r\"video_animal2_proyeccion_SeqDA/*\"))))\n",
    "            #print(\"dir\")\n",
    "            #for dir_i in dir:\n",
    "            #    print(dir_i)\n",
    "            if (\"ordenados\"==False):\n",
    "                elordendelosarchivosordenados=(\"1OR, 90L, 90LF, 90R, 90RF, F, UD, UDF\")\n",
    "            \n",
    "            #####OBTENER NOMBRE ARCHIVOS######\n",
    "            #####OBTENER NOMBRE ARCHIVOS######\n",
    "            #####OBTENER NOMBRE ARCHIVOS######\n",
    "            print(\"lst_nombreFilesOut\")\n",
    "            \n",
    "            #lst_nombreFiles=sorted(glob(r\"./\"+r\"COLAB_instance-level-human-parsing2/embryoDataset\"+r\"/\"+r\"video_animal2_proyeccion_SeqDA/*\"))\n",
    "            lst_nombreFiles=sorted(glob(r\"./\"+r\"COLAB_instance-level-human-parsing2/embryoDataset\"+r\"/\"+r\"video_animal2_proyeccion_SeqDA2/*\"))#20230123_1544\n",
    "            lst_nombreFiles=lst_test_images\n",
    "            \n",
    "            \n",
    "            import re\n",
    "            lst_nombreFilesOut=[]\n",
    "            for lst_nombreFiles_i in lst_nombreFiles:\n",
    "                aux=re.search(r\"[^/]+$\", lst_nombreFiles_i)[0]\n",
    "                aux=re.match(r\".*(?=\\.)\",aux)[0]\n",
    "                lst_nombreFilesOut.append(aux)\n",
    "\n",
    "\n",
    "            \n",
    "                #print(aux)\n",
    "            #print(\"lst_nombreFilesOut: \",lst_nombreFilesOut)\n",
    "            #####OBTENER NOMBRE ARCHIVOS######\n",
    "            #####OBTENER NOMBRE ARCHIVOS######\n",
    "            #####OBTENER NOMBRE ARCHIVOS######\n",
    "            \n",
    "            \n",
    "            i=0#20230613\n",
    "            for lst_preds_i,lst_nombreFilesOut_i  in zip(self.lst_predsConArgmax,lst_nombreFilesOut): \n",
    "                \n",
    "                print(\"lst_nombreFilesOut_i: \",lst_nombreFilesOut_i)\n",
    "                \n",
    "                \n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                #print(\"lst_preds_i: \",lst_preds_i)\n",
    "                #mi = tf.keras.metrics.MeanIoU(num_classes=num_classesIn)\n",
    "                #mi.update_state(test_masksIM[i], self.lst_predsConArgmax[i]) #True, pred\n",
    "                #aux_mi = (mi.result().numpy())\n",
    "\n",
    "                \n",
    "                #print(\"objeto_class_MaImMo2mIoU().calcular_numpy_postPrediction_mIoU\")\n",
    "                #Esto deberia dar iouClass0=0/2=0; iouClass1=2/4=1/2; miou=(iou0+iou1)/2=1/4=0.25\n",
    "                print(\"############\")\n",
    "                \n",
    "\n",
    "                #print(\"objeto_class_MaImMo2mIoU().calcular_tf_postPrediction_mIoU\")\n",
    "                \n",
    "                aux_mi1=class_MaskImageModel2mIoU().calcular_TFreadIm_model_TFmIoU_f1(str_directorioRaiz = str_data_dirIn, \n",
    "                                                                                      str_directorioMascara = str_mask_folderIn, #r\"EVLstack_SeqDA\", #20230610\n",
    "                                                                                      #directorioImagen = r\"video_animal2_proyeccion_SeqDA\",\n",
    "                                                                                      str_directorioImagen = str_raw_folderIn, #r\"video_animal2_proyeccion_SeqDA2\",#20230123_1544#20230610\n",
    "                                                                                      #nombreArchivoImagen = r\"UDF0085\",                                        \n",
    "                                                                                      str_nombreArchivoImagen = lst_nombreFilesOut_i,                                        \n",
    "                                                                                      kerFunc_modelIn = self.model,\n",
    "                                                                                      int_IMAGE_SIZEIn=self.int_IMAGE_SIZE,\n",
    "                                                                                      int_num_classesIn=self.int_NUM_CLASSES)\n",
    "                print(\"aux_mi1\", aux_mi1)\n",
    "                print(\"###############\")\n",
    "                \n",
    "                if False:\n",
    "                    aux_mi2=class_MaskImageModel2mIoU().calcular_TFreadIm_model_NPmIoU2Clases_f2(str_directorioRaiz = str_data_dirIn,#20230121_0345 \n",
    "                                                                                                 str_directorioMascara = r\"EVLstack_SeqDA\", #20230121_0345\n",
    "                                                                                                 #directorioImagen = r\"video_animal2_proyeccion_SeqDA\",#20230121_0345\n",
    "                                                                                                 str_directorioImagen = r\"video_animal2_proyeccion_SeqDA2\",#20230123_1544\n",
    "                                                                                                 #nombreArchivoImagen = r\"UDF0085\",                                        \n",
    "                                                                                                 str_nombreArchivoImagen = lst_nombreFilesOut_i,#20230121_0345\n",
    "                                                                                                 kerFunc_modelIn = self.model)#20230121_0345\n",
    "                    print(\"aux_mi2\", aux_mi2)\n",
    "\n",
    "                if False:\n",
    "                    print(\"###############\")\n",
    "                    aux_mi3=class_MaskImageModel2mIoU().calcular_CV2readIm_model_TFmIoU_f3(str_directorio_imgMask=str_DATA_DIR+r\"/\"+r\"EVLstack_SeqDA\"+r\"/\"+lst_nombreFilesOut_i+r\".png\", #20230119_14:58\n",
    "                                                                                           #directorioimgTest=DATA_DIR+r\"/\"+r\"video_animal2_proyeccion_SeqDA\"+r\"/\"+lst_nombreFilesOut_i+r\".jpg\",#20230119_14:58\n",
    "                                                                                           str_directorioimgTest=str_DATA_DIR+r\"/\"+r\"video_animal2_proyeccion_SeqDA2\"+r\"/\"+lst_nombreFilesOut_i+r\".png\",#20230121_0345\n",
    "                                                                                           kerFunc_modelIn=self.model,\n",
    "                                                                                           int_num_classesIn=self.int_NUM_CLASSES)#20230119_14:58\n",
    "                    print(\"aux_mi3\", aux_mi3)\n",
    "                \n",
    "                    print(\"###############\")\n",
    "                    aux_mi4=class_MaskImageModel2mIoU().calcular_CV2readIm_model_NPmIoU2Clases_f4(str_directorio_imgMask=str_DATA_DIR+r\"/\"+r\"EVLstack_SeqDA\"+r\"/\"+lst_nombreFilesOut_i+r\".png\", #20230119_14:58\n",
    "                                                                                                  #directorioimgTest=str_DATA_DIR+r\"/\"+r\"video_animal2_proyeccion_SeqDA\"+r\"/\"+lst_nombreFilesOut_i+r\".jpg\",#20230119_14:58\n",
    "                                                                                                  str_directorioimgTest=str_DATA_DIR+r\"/\"+r\"video_animal2_proyeccion_SeqDA2\"+r\"/\"+lst_nombreFilesOut_i+r\".png\",#20230121_0345\n",
    "                                                                                                  kerFunc_modelIn=self.model)#20230119_14:58\n",
    "                    print(\"aux_mi4\", aux_mi4)\n",
    "                \n",
    "                print(\"###############\")\n",
    "                aux_mi5=class_MaskImageModel2mIoU().calcular_model_TFmIoU_f5(et_3DXX1_imgMaskIn=self.test_masksIM[i], \n",
    "                                                                             et_3DXX3_imgTestIn=self.test_imagesIM[i], \n",
    "                                                                             kerFunc_modelIn=self.model, \n",
    "                                                                             int_num_classesIn=self.int_NUM_CLASSES)\n",
    "                print(\"aux_mi5\", aux_mi5)\n",
    "                \n",
    "                if False:\n",
    "                    print(\"###############\")\n",
    "                    aux_mi6=class_MaskImageModel2mIoU().calcular_model_NPmIoU2Clases_f6(et_3DXX1_imgMaskIn=self.test_masksIM[i], \n",
    "                                                                                        et_3DXX3_imgTestIn=self.test_imagesIM[i], \n",
    "                                                                                        kerFunc_modelIn=self.model)\n",
    "                    print(\"aux_mi6\", aux_mi6)\n",
    "                \n",
    "                print(\"###############\")\n",
    "                aux_mi7=class_MaskImageModel2mIoU().calcular_postPrediction_TFmIoU_f7(et_3DXX1_imgMaskIn=self.test_masksIM[i], \n",
    "                                                                                      nda_2DXX_imgTestPredictedIn=self.lst_predsConArgmax[i], \n",
    "                                                                                      int_num_classesIn=self.int_NUM_CLASSES)            \n",
    "                print(\"aux_mi7\", aux_mi7)\n",
    "                \n",
    "                if(str_DatasetNombre==\"DatasetPascal\"):\n",
    "                    aux_mi7_IL=class_MaskImageModel2mIoU().calcular_postPrediction_TFmIoU_f7(et_3DXX1_imgMaskIn=self.test_masksIM[i], \n",
    "                                                                                          nda_2DXX_imgTestPredictedIn=self.lst_predsConArgmax[i], \n",
    "                                                                                          int_num_classesIn=self.int_NUM_CLASSES,\n",
    "                                                                                          nt_int_ignoreLabelIn=21)            \n",
    "                    print(\"aux_mi7_IL\", aux_mi7_IL)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                if False:\n",
    "                    print(\"###############\")\n",
    "                    aux_mi8=class_MaskImageModel2mIoU().calcular_postPrediction_NPmIoU2Clases_f8(et_3DXX1_imgMaskIn=self.test_masksIM[i], \n",
    "                                                                                                 nda_2DXX_imgTestPredictedIn=self.lst_predsConArgmax[i])\n",
    "                    print(\"aux_mi8\", aux_mi8)\n",
    "                print(\"###############\")\n",
    "                print(\"###############\")\n",
    "                print(\"###############\")\n",
    "                 \n",
    "                \n",
    "                self.lst_miouINDconLib1.append(aux_mi1)\n",
    "                #self.lst_miouINDconLib2.append(aux_mi2)\n",
    "                #self.lst_miouINDconLib3.append(aux_mi3)\n",
    "                #self.lst_miouINDconLib4.append(aux_mi4)#20230119_14:58\n",
    "                self.lst_miouINDconLib5.append(aux_mi5)#20230121_0345\n",
    "                #self.lst_miouINDconLib6.append(aux_mi6)#20230121_1436\n",
    "                self.lst_miouINDconLib7.append(aux_mi7)\n",
    "                #self.lst_miouINDconLib8.append(aux_mi8)\n",
    "                if(str_DatasetNombre==\"DatasetPascal\"):\n",
    "                    self.lst_miouINDconLib7_IL.append(aux_mi7_IL)\n",
    "                \n",
    "                i+=1\n",
    "\n",
    "            dict_miouINDconLib1 = {lst_test_images[i]: self.lst_miouINDconLib1[i] for i in range(len(lst_test_images))}\n",
    "            #dict_miouINDconLib2 = {lst_test_images[i]: self.lst_miouINDconLib2[i] for i in range(len(lst_test_images))}\n",
    "            #dict_miouINDconLib3 = {lst_test_images[i]: self.lst_miouINDconLib3[i] for i in range(len(lst_test_images))}\n",
    "            #dict_miouINDconLib4 = {lst_test_images[i]: self.lst_miouINDconLib4[i] for i in range(len(lst_test_images))}#20230119_14:58\n",
    "            dict_miouINDconLib5 = {lst_test_images[i]: self.lst_miouINDconLib5[i] for i in range(len(lst_test_images))}#20230121_0345\n",
    "            #dict_miouINDconLib6 = {lst_test_images[i]: self.lst_miouINDconLib6[i] for i in range(len(lst_test_images))}#20230121_1436\n",
    "            dict_miouINDconLib7 = {lst_test_images[i]: self.lst_miouINDconLib7[i] for i in range(len(lst_test_images))}#20230121_1436\n",
    "            #dict_miouINDconLib8 = {lst_test_images[i]: self.lst_miouINDconLib8[i] for i in range(len(lst_test_images))}#20230121_1436\n",
    "            if(str_DatasetNombre==\"DatasetPascal\"):\n",
    "                dict_miouINDconLib7_IL = {lst_test_images[i]: self.lst_miouINDconLib7_IL[i] for i in range(len(lst_test_images))}#20230121_1436\n",
    "\n",
    "            print(\"este es como el promedio\")\n",
    "            self.miouINDconLib1 = sum(self.lst_miouINDconLib1) / len(self.lst_miouINDconLib1)  \n",
    "            #self.miouINDconLib2 = sum(self.lst_miouINDconLib2) / len(self.lst_miouINDconLib2)  \n",
    "            #self.miouINDconLib3 = sum(self.lst_miouINDconLib3) / len(self.lst_miouINDconLib3) \n",
    "            #self.miouINDconLib4 = sum(self.lst_miouINDconLib4) / len(self.lst_miouINDconLib4) #20230119_14:58\n",
    "            self.miouINDconLib5 = sum(self.lst_miouINDconLib5) / len(self.lst_miouINDconLib5) #20230121_0345\n",
    "            #self.miouINDconLib6 = sum(self.lst_miouINDconLib6) / len(self.lst_miouINDconLib6) #20230121_1436\n",
    "            self.miouINDconLib7 = sum(self.lst_miouINDconLib7) / len(self.lst_miouINDconLib7) #20230121_1436\n",
    "            #self.miouINDconLib8 = sum(self.lst_miouINDconLib8) / len(self.lst_miouINDconLib8) #20230121_1436\n",
    "            if(str_DatasetNombre==\"DatasetPascal\"):\n",
    "                self.miouINDconLib7_IL = sum(self.lst_miouINDconLib7_IL) / len(self.lst_miouINDconLib7_IL) #20230121_1436\n",
    "                \n",
    "            # Printing resultant dictionary\n",
    "            \n",
    "            print(\"Experimental miou promedio self.miouINDconLib1: \", self.miouINDconLib1)\n",
    "            print(\"Experimental miou promedio self.miouINDconLib5: \", self.miouINDconLib5)\n",
    "            print(\"Experimental miou promedio self.miouINDconLib7: \", self.miouINDconLib7)\n",
    "            if(str_DatasetNombre==\"DatasetPascal\"):\n",
    "                print(\"Experimental miou promedio self.miouINDconLib7_IL: \", self.miouINDconLib7_IL)\n",
    "            \n",
    "            if False:\n",
    "                #print(\"dict_miouINDconLib1: \")\n",
    "                print(\"\\x1b[34m\\\"Class Deeplab: calcular_numpy_postPrediction_mIoU\\\"\\x1b[0m\")\n",
    "                for item in dict_miouINDconLib1.items():\n",
    "                    print(item*100)\n",
    "\n",
    "                #print(\"dict_miouINDconLib2: \")\n",
    "                print(\"\\x1b[34m\\\"Class Deeplab: calcular_tf_postPrediction_mIoU\\\"\\x1b[0m\")\n",
    "                for item in dict_miouINDconLib2.items():\n",
    "                    print(item*100)\n",
    "\n",
    "                print(\"\\x1b[34m\\\"Class Deeplab: calcular_tf_readIm_tf_model_mIoUl\\\"\\x1b[0m\")\n",
    "                for item in dict_miouINDconLib3.items():\n",
    "                    print(item*100)\n",
    "\n",
    "                print(\"\\x1b[34m\\\"Class Deeplab: calcular_opencv_readIm_tf_model_mIoU\\\"\\x1b[0m\")#20230119_14:58\n",
    "                for item in dict_miouINDconLib4.items():#20230119_14:58\n",
    "                    print(item*100)#20230119_14:58\n",
    "\n",
    "            \n",
    "        \n",
    "        #MIOU SOLO DE LA PRIMERA IMAGEN\n",
    "        #MIOU SOLO DE LA PRIMERA IMAGEN\n",
    "        #MIOU SOLO DE LA PRIMERA IMAGEN\n",
    "        \n",
    "        \n",
    "\n",
    "        if(\"PrimeraImagenMioU\"==\"PrimeraImagenMioU\"):\n",
    "        #if(False):\n",
    "            lst_test_masks0=[lst_test_masks[0]]\n",
    "            lst_test_images0=[lst_test_images[0]]\n",
    "            self.test_masksIM0 = self.load_dataVBS(lst_test_masks0, mask=True, to_tensor=False, img_Size1=self.int_IMAGE_SIZE)\n",
    "            self.lst_predsConArgmax0=self.calc_predictionsVBSConArgmax(lst_test_images0, self.model, img_Size2=self.int_IMAGE_SIZE) \n",
    "            self.lst_predsSinArgmax0=self.calc_predictionsVBSSinArgmax(lst_test_images0, self.model, img_Size2=self.int_IMAGE_SIZE)#es una lista por eso la modifico abajo     \n",
    "            self.lst_predsSinArgmax0=self.lst_predsSinArgmax0[0]\n",
    "        \n",
    "            m0 = tf.keras.metrics.MeanIoU(num_classes=int_num_classesIn)\n",
    "            #i=0\n",
    "            #for lst_preds_i in self.lst_preds0: \n",
    "            m0.update_state(self.test_masksIM0, self.lst_predsConArgmax0)  \n",
    "                #m0.update_state(test_masksIM[i], self.lst_preds[i]) \n",
    "            #    i+=1\n",
    "            self.miou0=m0.result().numpy()*100\n",
    "            print(\"\\x1b[34m\\\"Class Deeplab: MIoU solo de la primera imagen\\\"\\x1b[0m\")\n",
    "            print(\"MIoU solo de la primera imagen usando self.test_masksIM0, self. lst_predsConArgmax0: \",lst_test_masks0)\n",
    "            print(\"MIoU solo de la primera imagen usando self.test_masksIM0, self. lst_predsConArgmax0: \",self.miou0)\n",
    "            \n",
    "            \n",
    "        if(self.str_entrenaroCargar==\"Train\"):\n",
    "            if(self.boo_guardarModeloIn==True):#20230119_1734\n",
    "                flo_rounded_miou = round(self.miouINDconLib7, 2)\n",
    "                if(str_DatasetNombre==\"DatasetPascal\"):\n",
    "                    flo_rounded_miou = round(self.miouINDconLib7_IL, 2)\n",
    "                    \n",
    "                str_rounded_miou = str(flo_rounded_miou).replace(\".\", \"_\")\n",
    "\n",
    "                flo_duration_seconds = flo_end_time - flo_start_time\n",
    "                flo_duration_hours = flo_duration_seconds / 3600  # Convert seconds to hours\n",
    "                flo_round_duration_hours = round(flo_duration_hours, 1)\n",
    "                str_round_duration_hours = str(flo_round_duration_hours).replace(\".\", \"_\")\n",
    "\n",
    "                #str_carpetaDir = str_data_dirIn.rsplit('/', 1)[-1]\n",
    "\n",
    "                #str_prefijoModel=str_carpetaDir+\"Miou\"+str(self.miouINDconLib7)+\"B\"+str(int_batch_sizeIn)+\"NC\"+str(int_num_classesIn)+\"Tra\"+str(int_num_train_imagesIn)+\"Val\"+str(int_num_val_imagesIn)+\"Tes\"+str(int_num_test_imagesIn)+\"Epo\"+str(int_epocasIn)#20230119_1734\n",
    "                str_prefijoModel=(str_DatasetNombre+\n",
    "                                 \"Ba\"+str(int_batch_sizeIn)+\n",
    "                                 \"NC\"+str(int_num_classesIn)+\n",
    "                                 #\"Se\"+str(int_seed)+\n",
    "                                 \"Tr\"+str(int_num_train_imagesIn)+\n",
    "                                 \"Va\"+str(int_num_val_imagesIn)+\n",
    "                                 \"Te\"+str(int_num_test_imagesIn)+\n",
    "                                 \"Ep\"+str(int_num_epochs)+#20230613\n",
    "                                 \"D\"+str_round_duration_hours+\n",
    "                                 \"Mi\"+str(str_rounded_miou)\n",
    "                                 )\n",
    "\n",
    "\n",
    "                str_nombreSavedModel=r'saved_models/'+str_fechaInicio+\"_A20220911_class_DeepLabVBS_\"+str_prefijoModel#\n",
    "                #print(r\"Guardando modelo en: \", r'saved_models/'+str_fecha+\"class_DeepLab\"+str_prefijoModel)\n",
    "                print(r\"Guardando modelo en: \", str_nombreSavedModel)\n",
    "                print(\"Training duration:\", str_round_duration_hours)\n",
    "                #self.model.save(r'saved_models/'+str_fecha+\"_A20220911_class_DeepLabVBS\"+str_prefijoModel)#20230119_1734\n",
    "                self.model.save(str_nombreSavedModel)#20230119_1734\n",
    "\n",
    "                #with open(str_nombreSavedModel+r\"/\"+\"Description.txt\", 'w') as file:\n",
    "                with open(str_nombreSavedModel+r\"/\"+r\"DescriptionVBS.txt\", 'w') as file:#20230613\n",
    "                    file.write(r\"str_nombreSavedModel: \"+str_nombreSavedModel)#20230613\n",
    "                    file.write(\"\\r\\n\")#20230613\n",
    "                    file.write(r\"self.int_IMAGE_SIZE: \"+str(self.int_IMAGE_SIZE))#20230613\n",
    "                    file.write(\"\\r\\n\")#20230613\n",
    "                    file.write(r\"int_seed: \"+str(int_seed))#20230613\n",
    "                \n",
    "                with open(str_nombreSavedModel+r\"/\"+r\"DatasetsFiles.txt\", 'w') as file:#20230613\n",
    "                    file.write(r\"Training files: \")\n",
    "                    file.write(\"\\r\\n\")\n",
    "                    for lst_train_images_i in lst_train_images:\n",
    "                        file.write(lst_train_images_i)\n",
    "                        file.write(\"\\r\\n\")\n",
    "                    file.write(r\"Validation files: \")\n",
    "                    file.write(\"\\r\\n\")\n",
    "                    for lst_val_images_i in lst_val_images:\n",
    "                        file.write(lst_val_images_i)\n",
    "                        file.write(\"\\r\\n\")\n",
    "                    file.write(r\"Testing files: \")\n",
    "                    file.write(\"\\r\\n\")\n",
    "                    for lst_test_images_i in lst_test_images:\n",
    "                        file.write(lst_test_images_i)\n",
    "                        file.write(\"\\r\\n\")\n",
    "        \n",
    "        boo_Plotear=False#20230613\n",
    "        if(boo_Plotear==True):#20230613\n",
    "            \n",
    "            if(str_DatasetNombre==\"DatasetPascal\"):\n",
    "                i=0\n",
    "                for lst_preds_i,lst_nombreFilesOut_i,(key_i, value_i)  in zip(self.lst_predsConArgmax,lst_nombreFilesOut, dict_miouINDconLib7_IL.items()):#20230614 dict_miouINDconLib7_IL este tiene ignore label\n",
    "                    print(lst_nombreFilesOut_i)\n",
    "                    self.func_plotearPascal(self.lst_predsConArgmax[i],\n",
    "                                                 str_imgIn=key_i,\n",
    "                                                 flo_miouIn=value_i\n",
    "                                                )\n",
    "                    i=i+1\n",
    "\n",
    "                \n",
    "                \n",
    "            if((str_DatasetNombre==\"DatasetEmbrion\") or (str_DatasetNombre==\"DatasetNeuron\") or (str_DatasetNombre==\"DatasetEmbrionSinDA\")):#20230703\n",
    "                i=0\n",
    "                for lst_preds_i,lst_nombreFilesOut_i,(key_i, value_i)  in zip(self.lst_predsConArgmax,lst_nombreFilesOut, dict_miouINDconLib7.items()):#20230614 Este dict_miouINDconLib7 no tiene ignore label\n",
    "                    print(\"Entro al plot de embrion\")\n",
    "                    self.func_plotearEmbrion(self.lst_predsConArgmax[i],\n",
    "                                             str_imgIn=key_i,\n",
    "                                             flo_miouIn=value_i\n",
    "                                            )\n",
    "                    i=i+1\n",
    "            \n",
    "\n",
    "        return(self.model)#20230610       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:    \n",
    "    import numpy as np\n",
    "    np.random.seed(11)\n",
    "\n",
    "    my_list = [1, 2, 3, 4, 5]\n",
    "    sample = np.random.choice(my_list, size=3, replace=False)\n",
    "    print(sample)  # Output: a random sample of 3 elements from my_list\n",
    "    sample = np.random.choice(my_list, size=3, replace=False)\n",
    "    print(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3' '4' '5']\n",
      "['3' '5' '4']\n"
     ]
    }
   ],
   "source": [
    "if True:    \n",
    "    import numpy as np\n",
    "    np.random.seed(11)\n",
    "\n",
    "    my_list = list(set([\"1\", \"2\", \"3\", \"4\", \"5\"]))\n",
    "    sample = np.random.choice(my_list, size=3, replace=False)\n",
    "    print(sample)  # Output: a random sample of 3 elements from my_list\n",
    "    sample = np.random.choice(my_list, size=3, replace=False)\n",
    "    print(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_dict = {\"key1\": \"value1\", \n",
    "#           \"key2\": \"value2\", \n",
    "#           \"key3\": \"value3\"}\n",
    "#\n",
    "#my_dict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_dict = {\"key1\": \"value1\", \"key2\": \"value2\", \"key3\": \"value3\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first_item = next(iter(my_dict.items()))\n",
    "\n",
    "#print(first_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class class_DeepLab(class_DeepLab):\n",
    "\n",
    "    def convolution_block(\n",
    "        self,\n",
    "        block_input,\n",
    "        num_filters=256,\n",
    "        kernel_size=3,\n",
    "        dilation_rate=1,\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "    ):\n",
    "        x = layers.Conv2D(\n",
    "            num_filters,\n",
    "            kernel_size=kernel_size,\n",
    "            dilation_rate=dilation_rate,\n",
    "            padding=\"same\",\n",
    "            use_bias=use_bias,\n",
    "            kernel_initializer=keras.initializers.HeNormal(),\n",
    "        )(block_input)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "    def DilatedSpatialPyramidPooling(self, dspp_input):\n",
    "        dims = dspp_input.shape\n",
    "        x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n",
    "        x = self.convolution_block(x, kernel_size=1, use_bias=True)\n",
    "        out_pool = layers.UpSampling2D(\n",
    "            size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation=\"bilinear\",\n",
    "        )(x)\n",
    "\n",
    "        out_1 = self.convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n",
    "        out_6 = self.convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n",
    "        out_12 = self.convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n",
    "        out_18 = self.convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n",
    "\n",
    "        x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n",
    "        output = self.convolution_block(x, kernel_size=1)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class class_DeepLab(class_DeepLab):\n",
    "    \n",
    "    def DeeplabV3Plus(self, \n",
    "                      image_size, \n",
    "                      num_classes\n",
    "                     ):\n",
    "        \n",
    "        #print(\"image_size: \", image_size)\n",
    "        model_input = keras.Input(shape=(image_size, image_size, 3))\n",
    "        resnet50 = keras.applications.ResNet50(\n",
    "            weights=\"imagenet\", include_top=False, input_tensor=model_input\n",
    "        )\n",
    "        x = resnet50.get_layer(\"conv4_block6_2_relu\").output\n",
    "        x = self.DilatedSpatialPyramidPooling(x)\n",
    "\n",
    "        input_a = layers.UpSampling2D(\n",
    "            size=(image_size // 4 // x.shape[1], image_size // 4 // x.shape[2]),\n",
    "            interpolation=\"bilinear\",\n",
    "        )(x)\n",
    "        input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n",
    "        input_b = self.convolution_block(input_b, num_filters=48, kernel_size=1)\n",
    "\n",
    "        x = layers.Concatenate(axis=-1)([input_a, input_b])\n",
    "        x = self.convolution_block(x)\n",
    "        x = self.convolution_block(x)\n",
    "        x = layers.UpSampling2D(\n",
    "            size=(image_size // x.shape[1], image_size // x.shape[2]),\n",
    "            interpolation=\"bilinear\",\n",
    "        )(x)\n",
    "        model_output = layers.Conv2D(num_classes, kernel_size=(1, 1), padding=\"same\", activation=\"softmax\")(x)\n",
    "        return keras.Model(inputs=model_input, outputs=model_output)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class class_DeepLab(class_DeepLab):\n",
    "    \n",
    "    def read_image(self,\n",
    "                   image_path, \n",
    "                   img_Size,\n",
    "                   mask=False,\n",
    "                   ):\n",
    "        \"\"\"Lee imagenes individuales, no listas\"\"\"\n",
    "        #self.func_datosVariable(image_path)\n",
    "        #print(\"read_image self.int_IMAGE_SIZE\", self.int_IMAGE_SIZE)\n",
    "    \n",
    "        image = tf.io.read_file(image_path)\n",
    "        if mask:\n",
    "            image = tf.image.decode_png(image, channels=1)\n",
    "            image.set_shape([None, None, 1])\n",
    "            #image = tf.image.resize(images=image, size=[self.int_IMAGE_SIZE, self.int_IMAGE_SIZE])\n",
    "            image = tf.image.resize(images=image, size=[img_Size, img_Size], method=\"nearest\")#20230610\n",
    "        else:\n",
    "            image = tf.image.decode_png(image, channels=3)\n",
    "            image.set_shape([None, None, 3])\n",
    "            image = tf.image.resize(images=image, size=[img_Size, img_Size])\n",
    "            #image = tf.image.resize(images=image, size=[self.int_IMAGE_SIZE, self.int_IMAGE_SIZE], method=\"nearest\")#20230610\n",
    "            image = image / 127.5 - 1\n",
    "        return image\n",
    "\n",
    "\n",
    "\n",
    "    def load_data(self, \n",
    "                  image_list, \n",
    "                  mask_list,\n",
    "                  #img_Size7\n",
    "                 ):\n",
    "        \n",
    "        img_Size7=self.int_IMAGE_SIZE#YellowFlag\n",
    "        image = self.read_image(image_list,\n",
    "                               img_Size7)\n",
    "        mask = self.read_image(mask_list,\n",
    "                               img_Size7,\n",
    "                               mask=True)\n",
    "        return image, mask\n",
    "\n",
    "\n",
    "    def data_generator(self, \n",
    "                       image_list, \n",
    "                       mask_list):\n",
    "        \n",
    "        dataset = tf.data.Dataset.from_tensor_slices((image_list, mask_list))\n",
    "        dataset = dataset.map(self.load_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        dataset = dataset.batch(self.int_BATCH_SIZE, drop_remainder=True)\n",
    "        return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class class_DeepLab(class_DeepLab):\n",
    "\n",
    "    def inferConArgmax(self, \n",
    "                       model, \n",
    "                       image_tensor):\n",
    "        \"\"\"\n",
    "        Inputs\n",
    "        model: 'keras.engine.functional.Functional'\n",
    "        image_tensor: tensorflow.python.framework.ops.EagerTensor\n",
    "        Outputs:\n",
    "        type(predictions):  <class 'numpy.ndarray'>\n",
    "        \n",
    "        Lee imagenes individuales, no listas\n",
    "        \"\"\"\n",
    "        \n",
    "        #print(\"inferConArgmax\")\n",
    "        #print(\"inferConArgmax type(model): \",type(model))\n",
    "        #print(\"hambre0\")\n",
    "        predictions = model.predict(np.expand_dims((image_tensor), \n",
    "                                                   axis=0))#Aqui muere especificamente\n",
    "        #print(\"hambre1\")\n",
    "        predictions = np.squeeze(predictions)\n",
    "        #print(\"hambre2\")\n",
    "        predictions = np.argmax(predictions, axis=2)\n",
    "        #print(\"hambre3\")\n",
    "        #print(\"inferConArgmax type(predictions): \",type(predictions))\n",
    "        return predictions\n",
    "\n",
    "    def calc_predictionsVBSConArgmax(self, \n",
    "                                     images_list, \n",
    "                                     model, \n",
    "                                     img_Size2\n",
    "                                    ):\n",
    "        \"\"\"\n",
    "        Inputs\n",
    "        images_list: class 'list'\n",
    "        model: class 'keras.engine.functional.Functional'\n",
    "        Outputs:\n",
    "        output: class 'list'\n",
    "        \n",
    "        Lee listas de imagenes individuales\n",
    "        \"\"\"\n",
    "        \n",
    "        #print(\"calc_predictionsVBSConArgmax\")\n",
    "        #print(\"calc_predictionsVBSConArgmax type(images_list): \",type(images_list))\n",
    "        #print(\"calc_predictionsVBSConArgmax type(model): \",type(model))\n",
    "        output=[]\n",
    "        for image_file in images_list:\n",
    "            #print(\"chao\")\n",
    "            #print(\"image_file: \",image_file)\n",
    "            #print(\"img_Size2: \",img_Size2)\n",
    "            image_tensor = self.read_image(image_file, \n",
    "                                           img_Size2)\n",
    "            #print(\"chao2\")\n",
    "            \n",
    "            if False:#20230610\n",
    "                str_dirModelLoadIn9=r\"20230709_0917_A20220911_class_DeepLabVBS_DatasetEmbrionBa3NC2Tr105Va10Te30Ep29D0_6Mi75_8\"\n",
    "                str_imgRawPathIn9=r\"./COLAB_instance-level-human-parsing2/embryoDataset/video_animal2_proyeccion_SeqDA2/1OR0000.png\"\n",
    "                image = tf.io.read_file(str_imgRawPathIn9)\n",
    "                image = tf.image.decode_png(image, channels=3)\n",
    "                image.set_shape([None, None, 3])\n",
    "                #image = tf.image.resize(images=image, size=[1024,1024])#20230610\n",
    "\n",
    "                nda_3DXX3_uint8_imgRGB = image.numpy()\n",
    "                Func_model=tf.keras.models.load_model(r\"saved_models/\"+str_dirModelLoadIn9) #20230119_1734\n",
    "                print(\"basket\")\n",
    "                Func_model.predict(np.expand_dims((nda_3DXX3_uint8_imgRGB / 127.5 - 1), \n",
    "                                           axis=0))#Loagregue 20290929\n",
    "                print(\"futbol\")\n",
    "                \n",
    "            #print(\"almuerzo\")\n",
    "            prediction_mask = self.inferConArgmax(image_tensor=image_tensor, #AQUI SE CAE 20230929\n",
    "                                                  model=model)\n",
    "            #print(\"chao3\")\n",
    "            output.append(prediction_mask)\n",
    "        #print(\"calc_predictionsVBSConArgmax type(output): \",type(output))\n",
    "        return(output)\n",
    "          #prediction_colormap = decode_segmentation_masks(prediction_mask, colormap, 20)\n",
    "          #overlay = get_overlay(image_tensor, prediction_colormap)\n",
    "          #plot_samples_matplotlib(\n",
    "          #    [image_tensor, overlay, prediction_colormap], figsize=(18, 14)\n",
    "          #)\n",
    "        \n",
    "    def calc_predictionsVBSSinArgmax(self, \n",
    "                                     images_list, \n",
    "                                     model,\n",
    "                                    img_Size2\n",
    "                                    ):\n",
    "        \"\"\"\n",
    "        Inputs\n",
    "        images_list: class 'list'\n",
    "        model: class 'keras.engine.functional.Functional'\n",
    "        Outputs:\n",
    "        output: class 'list'. Lista con cada elemento de dimensiones (batchxaltoxanchox2)\n",
    "        \n",
    "        Lee listas de imagenes individuales\n",
    "        \"\"\"\n",
    "        \n",
    "        #print(\"calc_predictionsVBSSinArgmax\")\n",
    "        def inferSinArgmax(model, image_tensor):\n",
    "            \"\"\"\n",
    "            Inputs\n",
    "            model: class 'keras.engine.functional.Functional'\n",
    "            image_tensor: class 'tensorflow.python.framework.ops.EagerTensor'\n",
    "            Outputs:\n",
    "            predictions: class 'numpy.ndarray'\n",
    "            \n",
    "            Lee imagenes individuales\n",
    "            \"\"\"\n",
    "            \n",
    "            \n",
    "            #print(\"inferSinArgmax inferSinArgmax\")\n",
    "            #print(\"inferSinArgmax type(image_tensor): \",type(image_tensor))\n",
    "            #print(\"inferSinArgmax type(model): \",type(model))\n",
    "            predictions = model.predict(np.expand_dims((image_tensor), axis=0))\n",
    "            #print(\"inferSinArgmax type(predictions): \",type(predictions))\n",
    "            return predictions\n",
    "        \n",
    "        #print(\"calc_predictionsVBSSinArgmax type(images_list): \",type(images_list))\n",
    "        #print(\"calc_predictionsVBSSinArgmax type(model): \",type(model))\n",
    "        output=[]\n",
    "        for image_file in images_list:\n",
    "            print(\"hola\")\n",
    "            image_tensor = self.read_image(image_file,\n",
    "                                          img_Size2)#va a tirar error porque no tiene imgsize de parametro\n",
    "            print(\"hola2\")\n",
    "            prediction_mask = inferSinArgmax(image_tensor=image_tensor, model=model)\n",
    "            output.append(prediction_mask)\n",
    "        #print(\"calc_predictionsVBSSinArgmax type(output): \",type(output))\n",
    "        return(output)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class class_DeepLab(class_DeepLab):\n",
    "    \n",
    "    def plot_predictions(self, images_list, colormap, model):\n",
    "        \n",
    "        def decode_segmentation_masks(mask, colormap, n_classes):\n",
    "            r = np.zeros_like(mask).astype(np.uint8)\n",
    "            g = np.zeros_like(mask).astype(np.uint8)\n",
    "            b = np.zeros_like(mask).astype(np.uint8)\n",
    "            for l in range(0, n_classes):\n",
    "                idx = mask == l\n",
    "                r[idx] = colormap[l, 0]\n",
    "                g[idx] = colormap[l, 1]\n",
    "                b[idx] = colormap[l, 2]\n",
    "            rgb = np.stack([r, g, b], axis=2)\n",
    "            return rgb\n",
    "        \n",
    "        def get_overlay(image, colored_mask):\n",
    "            image = tf.keras.preprocessing.image.array_to_img(image)\n",
    "            image = np.array(image).astype(np.uint8)\n",
    "            overlay = cv2.addWeighted(image, 0.35, colored_mask, 0.65, 0)\n",
    "            return overlay             \n",
    "    \n",
    "        \n",
    "        def plot_samples_matplotlib(display_list, figsize=(5, 3)):\n",
    "            _, axes = plt.subplots(nrows=1, ncols=len(display_list), figsize=figsize)\n",
    "            for i in range(len(display_list)):\n",
    "                if display_list[i].shape[-1] == 3:\n",
    "                    axes[i].imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "                else:\n",
    "                    axes[i].imshow(display_list[i])\n",
    "            plt.show()\n",
    "\n",
    "        \n",
    "        for image_file in images_list:\n",
    "            image_tensor = self.read_image(image_file)#va a tirar error porque no tiene imgsize de parametro\n",
    "            prediction_mask = self.inferConArgmax(image_tensor=image_tensor, model=model)\n",
    "            prediction_colormap = decode_segmentation_masks(prediction_mask, colormap, 20)\n",
    "            overlay = get_overlay(image_tensor, prediction_colormap)\n",
    "            plot_samples_matplotlib(\n",
    "              [image_tensor, overlay, prediction_colormap], figsize=(18, 14)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class class_DeepLab(class_DeepLab):\n",
    "\n",
    "    def load_dataVBS(self, \n",
    "                     image_list, \n",
    "                     mask, \n",
    "                     to_tensor,\n",
    "                     img_Size1):\n",
    "        \"\"\"\n",
    "        Inputs\n",
    "        image_list: 'class 'list''\n",
    "        mask: class 'bool'\n",
    "        to_tensor: ?\n",
    "        \n",
    "        Outputs:\n",
    "        output: 'class 'list''\n",
    "        \n",
    "        Outputs: Lista de read images\n",
    "        \"\"\"\n",
    "        \n",
    "        #print(\"load_dataVBS\")\n",
    "        #print(\"load_dataVBS type(image_list): \",type(image_list))\n",
    "        #print(\"load_dataVBS type(mask): \",type(mask))\n",
    "        output=[]\n",
    "        for image_list_i in image_list:\n",
    "            image = self.read_image(image_list_i, \n",
    "                                    img_Size1,\n",
    "                                    mask)\n",
    "            output.append(image)\n",
    "\n",
    "        #if(to_tensor==True):\n",
    "        #    output=tf.convert_to_tensor(output)\n",
    "        #print(\"load_dataVBS type(output): \",type(output))\n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    class class_DeepLab(class_DeepLab):\n",
    "\n",
    "        def func_datosVariable(self, variableIn):\n",
    "            #strvariableIn=str(variableIn)\n",
    "            #strvariableIn = f'{variableIn=}'.split('=')[0]\n",
    "            strvariableIn=\"variableIn\"\n",
    "\n",
    "            print(\"type(\"+strvariableIn+r\"): \",type(variableIn))\n",
    "            print(strvariableIn+r\".shape: \",variableIn.shape)\n",
    "            print(r\"np.min(\"+strvariableIn+r\"): \",np.min(variableIn))\n",
    "            print(r\"np.max(\"+strvariableIn+r\"): \",np.max(variableIn))\n",
    "            print(r\"np.unique(\"+strvariableIn+r\"): \",np.unique(variableIn))\n",
    "            print(r\"len(np.unique(\"+strvariableIn+r\")): \",len(np.unique(variableIn)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class class_DeepLab(class_DeepLab):        \n",
    "\n",
    "    def func_plotearPascal(self,\n",
    "                           nda_2DXX_ImgIn,\n",
    "                           str_imgIn,#para el titulo\n",
    "                           flo_miouIn#para el titulo\n",
    "                           ):\n",
    "        import matplotlib.pyplot as plt\n",
    "        import numpy as np\n",
    "\n",
    "        # Define the color palette for PASCAL VOC 21 classes\n",
    "        colors = [\n",
    "            [0, 0, 0],        # Background (black)\n",
    "            [128, 0, 0],      # Aeroplane (maroon)\n",
    "            [0, 128, 0],      # Bicycle (green)\n",
    "            [128, 128, 0],    # Bird (olive)\n",
    "            [0, 0, 128],      # Boat (navy)\n",
    "            [128, 0, 128],    # Bottle (purple)\n",
    "            [0, 128, 128],    # Bus (teal)\n",
    "            [128, 128, 128],  # Car (gray)\n",
    "            [64, 0, 0],       # Cat (dark maroon)\n",
    "            [192, 0, 0],      # Chair (dark red)\n",
    "            [64, 128, 0],     # Cow (dark green)\n",
    "            [192, 128, 0],    # Dining Table (dark olive)\n",
    "            [64, 0, 128],     # Dog (dark purple)\n",
    "            [192, 0, 128],    # Horse (dark magenta)\n",
    "            [64, 128, 128],   # Motorbike (dark cyan)\n",
    "            [192, 128, 128],  # Person (light gray)\n",
    "            [0, 64, 0],       # Potted Plant (dark green)\n",
    "            [128, 64, 0],     # Sheep (brown)\n",
    "            [0, 192, 0],      # Sofa (green)\n",
    "            [128, 192, 0],    # Train (olive)\n",
    "            [0, 64, 128],     # TV/Monitor (dark blue)\n",
    "            [255, 255, 255],  # IgnoreLabel\n",
    "        ]\n",
    "\n",
    "        # Define the class names for PASCAL VOC 21 classes\n",
    "        class_names = [\n",
    "            \"Background\",\n",
    "            \"Aeroplane\",\n",
    "            \"Bicycle\",\n",
    "            \"Bird\",\n",
    "            \"Boat\",\n",
    "            \"Bottle\",\n",
    "            \"Bus\",\n",
    "            \"Car\",\n",
    "            \"Cat\",\n",
    "            \"Chair\",\n",
    "            \"Cow\",\n",
    "            \"Dining Table\",\n",
    "            \"Dog\",\n",
    "            \"Horse\",\n",
    "            \"Motorbike\",\n",
    "            \"Person\",\n",
    "            \"Potted Plant\",\n",
    "            \"Sheep\",\n",
    "            \"Sofa\",\n",
    "            \"Train\",\n",
    "            r\"TV/Monitor\",\n",
    "            \"IgnoreLabel\"\n",
    "        ]\n",
    "\n",
    "        # Convert color values from 0-255 to the range of 0-1\n",
    "        colors = np.array(colors) / 255.0\n",
    "\n",
    "        # Generate example data with square image dimensions\n",
    "        #data = np.random.randint(0, 21, size=(100, 100))\n",
    "        #data = np.repeat(np.arange(21).reshape(-1, 1), 21, axis=1)\n",
    "\n",
    "        # Get unique values in data and their corresponding indices\n",
    "        unique_values, indices = np.unique(nda_2DXX_ImgIn, return_inverse=True)\n",
    "\n",
    "        # Map the indices to colors\n",
    "        unique_colors = colors[unique_values]\n",
    "        \n",
    "        \n",
    "        plt.figure(figsize=(10, 10))\n",
    "        # Plot using the PASCAL VOC color palette\n",
    "        #plt.imshow(nda_2DXX_ImgIn, cmap=plt.cm.colors.ListedColormap(colors))\n",
    "        plt.imshow(indices.reshape(nda_2DXX_ImgIn.shape), cmap=plt.cm.colors.ListedColormap(unique_colors))#20230615 \n",
    "        #plt.colorbar(ticks=np.arange(21))\n",
    "\n",
    "\n",
    "\n",
    "        # Define legend data\n",
    "        legend_data = [\n",
    "            [i, colors[i], class_names[i]]\n",
    "            for i in range(len(colors))\n",
    "        ]\n",
    "\n",
    "        # Create legend handles and labels\n",
    "        handles = [\n",
    "            plt.Rectangle((0, 0), 1, 1, color=c)\n",
    "            for k, c, n in legend_data\n",
    "        ]\n",
    "        labels = [n for k, c, n in legend_data]\n",
    "        \n",
    "        ##Para mostrarlo en la legenda\n",
    "        lst_uniques=np.unique(nda_2DXX_ImgIn).tolist()\n",
    "        lst_str_uniquesNames=[]\n",
    "        for lst_uniques_i in lst_uniques:\n",
    "            print(\"lst_uniques_i\", lst_uniques_i)\n",
    "            print(\"class_names[lst_uniques_i]\", class_names[lst_uniques_i])\n",
    "            lst_str_uniquesNames.append(class_names[lst_uniques_i])\n",
    "        ##Para mostrarlo en la legenda\n",
    "        \n",
    "        #print(\"miou: \",miouIn)\n",
    "        # Display legend\n",
    "        plt.legend(handles=handles, labels=labels, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "        plt.title(str(lst_uniques)+str(lst_str_uniquesNames)+str_imgIn+str(flo_miouIn))\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Ojo esta malo en general este, muestra color blanco en otras clases\")#YellowFLAG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class class_DeepLab(class_DeepLab):        \n",
    "\n",
    "    def func_plotearEmbrion(self,\n",
    "                           nda_2DXX_ImgIn,\n",
    "                           str_imgIn,\n",
    "                           flo_miouIn\n",
    "                           ):\n",
    "        import matplotlib.pyplot as plt\n",
    "        import numpy as np\n",
    "\n",
    "        # Define the color palette for PASCAL VOC 21 classes\n",
    "        colors = [\n",
    "            [0, 0, 0],        # Background (black)\n",
    "            [255, 255, 255],  # Embrion\n",
    "        ]\n",
    "\n",
    "        # Define the class names for PASCAL VOC 21 classes\n",
    "        class_names = [\n",
    "            \"Background\",\n",
    "            \"Embryo\",\n",
    "        ]\n",
    "\n",
    "        # Convert color values from 0-255 to the range of 0-1\n",
    "        colors = np.array(colors) / 255.0\n",
    "        \n",
    "        # Get unique values in data and their corresponding indices\n",
    "        unique_values, indices = np.unique(nda_2DXX_ImgIn, return_inverse=True)\n",
    "\n",
    "        # Map the indices to colors\n",
    "        unique_colors = colors[unique_values]\n",
    "        \n",
    "\n",
    "        # Generate example data with square image dimensions\n",
    "        #data = np.random.randint(0, 21, size=(100, 100))\n",
    "        #data = np.repeat(np.arange(21).reshape(-1, 1), 21, axis=1)\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        # Plot using the PASCAL VOC color palette\n",
    "        plt.imshow(nda_2DXX_ImgIn, cmap=plt.cm.colors.ListedColormap(colors))\n",
    "        #plt.colorbar(ticks=np.arange(21))\n",
    "\n",
    "\n",
    "\n",
    "        # Define legend data\n",
    "        legend_data = [\n",
    "            [i, colors[i], class_names[i]]\n",
    "            for i in range(len(colors))\n",
    "        ]\n",
    "\n",
    "        # Create legend handles and labels\n",
    "        handles = [\n",
    "            plt.Rectangle((0, 0), 1, 1, color=c)\n",
    "            for k, c, n in legend_data\n",
    "        ]\n",
    "        labels = [n for k, c, n in legend_data]\n",
    "        \n",
    "        lst_uniques=np.unique(nda_2DXX_ImgIn).tolist()\n",
    "        lst_str_uniquesNames=[]\n",
    "        for lst_uniques_i in lst_uniques:\n",
    "            print(\"lst_uniques_i\", lst_uniques_i)\n",
    "            print(\"class_names[lst_uniques_i]\", class_names[lst_uniques_i])\n",
    "            lst_str_uniquesNames.append(class_names[lst_uniques_i])\n",
    "        \n",
    "        # Display legend\n",
    "        plt.legend(handles=handles, labels=labels, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "        plt.title(str(lst_uniques)+str(lst_str_uniquesNames)+str_imgIn+str(flo_miouIn))\n",
    "        plt.show()\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#array_1d = np.array([1, 2, 3, 4, 5])\n",
    "#type(np.unique(array_1d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# class_DeepLab_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class class_DeepLab_Test():#Entrenar modelo\n",
    "    def mein(self,\n",
    "            str_dataset2,\n",
    "            str_entrenaroCargar12,\n",
    "            str_dirModelLoad12,\n",
    "            boo_activarCRFIn1\n",
    "            ):\n",
    "    \n",
    "        \n",
    "        \"\"\"Se carga el modelo (o entrena), y luego se le pasa una imagen dada por str_filename \n",
    "        para que obtenga el miou de deeplab, miou con CRF y plot. La config del CRF esta fija\n",
    "        es mas que nada solo por cumplir y ponerlo en el informe de que esta funcionando \n",
    "        deeplabV3+ mas CRF.\n",
    "        Esta pensada para la figura Objective 2: Implement state-of-the-art methods, que se tiene\n",
    "        la imagen procesada por deeplab y gracias a esta funcion la imagen de deeplab+crf (con parametros fijos, sin optimizar de ninguna manera\n",
    "        \"\"\"\n",
    "        \n",
    "        #str_entrenaroCargar1=\"Train\"\n",
    "        #str_entrenaroCargar1=str_entrenaroCargar12 #20230613\n",
    "        #str_dirModelLoad1=r\"20230119_1932class_DeepLabembrionB3NC2Tra900Val100Tes100Epo100\"\n",
    "        #str_dirModelLoad1=str_dirModelLoad12\n",
    "        boo_guardarModeloIn1=True#20230610    \n",
    "        int_batch_sizeIn1=3#parece que no se puede 4 el monstruito\n",
    "        int_epocasIn1=10000 #Tiene early stopping\n",
    "        #str_dataset=\"embrion\"\n",
    "        #str_dataset=str_dataset2 #20230613\n",
    "       \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        #if (str_dataset==\"embrion\"):\n",
    "        if (str_dataset2==\"embrion\"):\n",
    "            int_image_sizeIn1=1024#20230613\n",
    "            int_num_classesIn1=2\n",
    "            #data_dirIn1=r\"./COLAB_instance-level-human-parsing2/embryoDataset\"\n",
    "            str_data_dirIn1=r\"COLAB_instance-level-human-parsing2/embryoDataset\" #PascalTrainVal\n",
    "            #data_dirIn1=r\"PascalTrainVal\" #PascalTrainVal\n",
    "            str_mask_folderIn1=r\"EVLstack_SeqDA\" #MasksIgnoreClass21\n",
    "            str_raw_folderIn1=r\"video_animal2_proyeccion_SeqDA2\" #Raws\n",
    "            #raw_folderIn1=r\"Raws\" #Raws\n",
    "            int_num_train_imagesIn1=105#900\n",
    "            int_num_val_imagesIn1=10#100\n",
    "            int_num_test_imagesIn1=30#100 \n",
    "            str_extensionRaw=r\".png\"\n",
    "            num_classes1=2\n",
    "            str_filename=r\"1OR0006\"#r\"UDF0019\"#Esta es de test. TIENE QUE SER DEL CONJUNTO DE TEST... CORRER DEEPLAB CON 1 SOLA EPOCH Y AHI SALEN PRINTEADAS LAS IMAGENES DE CADA CONJUNTO\n",
    "            tpl_ParametroXY1=(1,1)\n",
    "            tpl_ParametroRGB1=(1,1,1)\n",
    "            int_pairwisebilateralCompat1=3\n",
    "            int_inference1=7\n",
    "            str_PairwiseoKernel1=\"GaussianoSmoothnessKernelYBilateraloAppearanceKernel\"\n",
    "            \n",
    "            \n",
    "        if (str_dataset2==\"embrion_sinDA\"):\n",
    "            int_image_sizeIn1=1024#20230613\n",
    "            int_num_classesIn1=2\n",
    "            #data_dirIn1=r\"./COLAB_instance-level-human-parsing2/embryoDataset\"\n",
    "            str_data_dirIn1=r\"embryoDataset_SinDA\" #PascalTrainVal\n",
    "            #data_dirIn1=r\"PascalTrainVal\" #PascalTrainVal\n",
    "            str_mask_folderIn1=r\"EVLstack_Seq\" #MasksIgnoreClass21\n",
    "            str_raw_folderIn1=r\"video_animal2_proyeccion_Seq\" #Raws\n",
    "            #raw_folderIn1=r\"Raws\" #Raws\n",
    "            int_num_train_imagesIn1=100\n",
    "            int_num_val_imagesIn1=10\n",
    "            int_num_test_imagesIn1=30 \n",
    "            str_extensionRaw=r\".png\"\n",
    "            num_classes1=2\n",
    "            str_filename=r\"1OR0111\"#TIENE QUE SER DEL CONJUNTO DE TEST... CORRER DEEPLAB CON 1 SOLA EPOCH Y AHI SALEN PRINTEADAS LAS IMAGENES DE CADA CONJUNTO\n",
    "            tpl_ParametroXY1=(1,1)\n",
    "            tpl_ParametroRGB1=(1,1,1)\n",
    "            int_pairwisebilateralCompat1=3\n",
    "            int_inference1=7\n",
    "            str_PairwiseoKernel1=\"GaussianoSmoothnessKernelYBilateraloAppearanceKernel\"\n",
    "            \n",
    "\n",
    "            #mask_folderIn1=r\"MasksIgnoreClass21\" #MasksIgnoreClass21\n",
    "        if (str_dataset2==\"pascal\"):  \n",
    "            int_image_sizeIn1=512#20230613 OJO ESTO QUIZAS LO HACE MEJORAR. El original deeplabv3+ es con 512 de size\n",
    "            int_num_classesIn1=22# Con 21 el loss es nan y 0 background\n",
    "            #data_dirIn1=r\"./COLAB_instance-level-human-parsing2/embryoDataset\"\n",
    "            #data_dirIn1=r\"COLAB_instance-level-human-parsing2/embryoDataset\" #PascalTrainVal\n",
    "            str_data_dirIn1=r\"PascalTrainVal\" #PascalTrainVal\n",
    "            #raw_folderIn1=r\"video_animal2_proyeccion_SeqDA2\" #Raws\n",
    "            str_mask_folderIn1=r\"MasksIgnoreClass21\" #MasksIgnoreClass21\n",
    "            str_raw_folderIn1=r\"Raws\" #Raws\n",
    "            #mask_folderIn1=r\"EVLstack_SeqDA\" #MasksIgnoreClass21\n",
    "            int_num_train_imagesIn1=9000\n",
    "            int_num_val_imagesIn1=2000\n",
    "            int_num_test_imagesIn1=1000 \n",
    "            str_extensionRaw=r\".jpg\"\n",
    "            num_classes1=22\n",
    "            str_filename=r\"2011_001253\"#El caballito. TIENE QUE SER DEL CONJUNTO DE TEST... CORRER DEEPLAB CON 1 SOLA EPOCH Y AHI SALEN PRINTEADAS LAS IMAGENES DE CADA CONJUNTO\n",
    "            tpl_ParametroXY1=(1,1)\n",
    "            tpl_ParametroRGB1=(1,1,1)\n",
    "            int_pairwisebilateralCompat1=3\n",
    "            int_inference1=7\n",
    "            str_PairwiseoKernel1=\"GaussianoSmoothnessKernelYBilateraloAppearanceKernel\"\n",
    "            \n",
    "        \n",
    "        if (str_dataset2==\"neuron\"):  \n",
    "            int_image_sizeIn1=512#20230613 OJO ESTO QUIZAS LO HACE MEJORAR. El original deeplabv3+ es con 512 de size\n",
    "            int_num_classesIn1=2# Con 21 el loss es nan y 0 background\n",
    "            #data_dirIn1=r\"./COLAB_instance-level-human-parsing2/embryoDataset\"\n",
    "            #data_dirIn1=r\"COLAB_instance-level-human-parsing2/embryoDataset\" #PascalTrainVal\n",
    "            str_data_dirIn1=r\"2D_Neuronal_dataset_Proc\" #PascalTrainVal\n",
    "            #raw_folderIn1=r\"video_animal2_proyeccion_SeqDA2\" #Raws\n",
    "            str_mask_folderIn1=r\"Masks\" #MasksIgnoreClass21\n",
    "            str_raw_folderIn1=r\"Raws\" #Raws\n",
    "            #mask_folderIn1=r\"EVLstack_SeqDA\" #MasksIgnoreClass21\n",
    "            int_num_train_imagesIn1=150#1400 Despues considera las de data augmentation\n",
    "            int_num_val_imagesIn1=30#100 Despues considera las de data augmentation\n",
    "            int_num_test_imagesIn1=30#100 Despues considera las de data augmentation\n",
    "            str_extensionRaw=r\".png\"\n",
    "            num_classes1=2\n",
    "            str_filename=r\"1OR0111\"#r\"B2_8_fh\"#una neuronita. TIENE QUE SER DEL CONJUNTO DE TEST... CORRER DEEPLAB CON 1 SOLA EPOCH Y AHI SALEN PRINTEADAS LAS IMAGENES DE CADA CONJUNTO\n",
    "            tpl_ParametroXY1=(1,1)\n",
    "            tpl_ParametroRGB1=(1,1,1)\n",
    "            int_pairwisebilateralCompat1=3\n",
    "            int_inference1=7\n",
    "            str_PairwiseoKernel1=\"GaussianoSmoothnessKernelYBilateraloAppearanceKernel\"\n",
    "            \n",
    "        if (str_dataset2==\"tissue\"):  \n",
    "            int_image_sizeIn1=512#20230613 OJO ESTO QUIZAS LO HACE MEJORAR. El original deeplabv3+ es con 512 de size\n",
    "            int_num_classesIn1=2# Con 21 el loss es nan y 0 background\n",
    "            #data_dirIn1=r\"./COLAB_instance-level-human-parsing2/embryoDataset\"\n",
    "            #data_dirIn1=r\"COLAB_instance-level-human-parsing2/embryoDataset\" #PascalTrainVal\n",
    "            str_data_dirIn1=r\"Warwick_QU_Dataset_Released 2016_07_08_Proc\" #PascalTrainVal\n",
    "            #raw_folderIn1=r\"video_animal2_proyeccion_SeqDA2\" #Raws\n",
    "            str_mask_folderIn1=r\"Masks\" #MasksIgnoreClass21\n",
    "            str_raw_folderIn1=r\"Raws\" #Raws\n",
    "            #mask_folderIn1=r\"EVLstack_SeqDA\" #MasksIgnoreClass21\n",
    "            int_num_train_imagesIn1=115#1400 Despues considera las de data augmentation\n",
    "            int_num_val_imagesIn1=25#100 Despues considera las de data augmentation\n",
    "            int_num_test_imagesIn1=25#100 Despues considera las de data augmentation\n",
    "            str_extensionRaw=r\".png\"\n",
    "            num_classes1=2\n",
    "            str_filename=r\"1OR0111\"#r\"B2_8_fh\"#una neuronita. TIENE QUE SER DEL CONJUNTO DE TEST... CORRER DEEPLAB CON 1 SOLA EPOCH Y AHI SALEN PRINTEADAS LAS IMAGENES DE CADA CONJUNTO\n",
    "            tpl_ParametroXY1=(1,1)\n",
    "            tpl_ParametroRGB1=(1,1,1)\n",
    "            int_pairwisebilateralCompat1=3\n",
    "            int_inference1=7\n",
    "            str_PairwiseoKernel1=\"GaussianoSmoothnessKernelYBilateraloAppearanceKernel\"\n",
    "\n",
    "\n",
    "        objeto_class_DeepLab=class_DeepLab()\n",
    "        objeto_class_DeepLab(str_entrenaroCargar12,\n",
    "                             str_dirModelLoad12,\n",
    "                             boo_guardarModeloIn1,\n",
    "                             int_image_sizeIn=int_image_sizeIn1, \n",
    "                             int_batch_sizeIn=int_batch_sizeIn1, \n",
    "\n",
    "                             int_num_classesIn=int_num_classesIn1,\n",
    "                             str_data_dirIn=str_data_dirIn1,\n",
    "                             str_mask_folderIn=str_mask_folderIn1,\n",
    "                             str_raw_folderIn=str_raw_folderIn1,                          \n",
    "\n",
    "                             int_num_train_imagesIn=int_num_train_imagesIn1, \n",
    "                             int_num_val_imagesIn=int_num_val_imagesIn1, \n",
    "                             int_num_test_imagesIn=int_num_test_imagesIn1, \n",
    "                             int_epocasIn=int_epocasIn1,\n",
    "                             boo_activarCRFIn=boo_activarCRFIn1\n",
    "                            )\n",
    "        \n",
    "        self.objeto_class_DeepLab=objeto_class_DeepLab\n",
    "        \n",
    "        \n",
    "        str_DATADIRMASK=r\"./\"+str_data_dirIn1+r\"/\"+str_mask_folderIn1+r\"/\"+str_filename+r\".png\"\n",
    "        str_DATADIRRAW=r\"./\"+str_data_dirIn1+r\"/\"+str_raw_folderIn1+r\"/\"+str_filename+str_extensionRaw\n",
    "        \n",
    "\n",
    "        if (\"TestearModeloConPredictsaStrPath\"==\"TestearModeloConPredictsaStrPath\"):\n",
    "            \n",
    "            \n",
    "                \n",
    "            test_masksIM8=self.objeto_class_DeepLab.load_dataVBS([str_DATADIRMASK], \n",
    "                                                                    mask=True, \n",
    "                                                                    to_tensor=False,\n",
    "                                                                 img_Size1=int_image_sizeIn1#self.int_IMAGE_SIZE\n",
    "                                                                )\n",
    "\n",
    "            lst_predsConArgmax8=self.objeto_class_DeepLab.calc_predictionsVBSConArgmax([str_DATADIRRAW], \n",
    "                                                                                        self.objeto_class_DeepLab.model,\n",
    "                                                                                        img_Size2=int_image_sizeIn1#self.int_IMAGE_SIZE\n",
    "                                                                                      )\n",
    "\n",
    "            lst_predsSinArgmax8=self.objeto_class_DeepLab.calc_predictionsVBSSinArgmax([str_DATADIRRAW], \n",
    "                                                                                        self.objeto_class_DeepLab.model,\n",
    "                                                                                       img_Size2=int_image_sizeIn1#self.int_IMAGE_SIZE                                                                                      \n",
    "                                                                                      )\n",
    "            lst_predsSinArgmax8=lst_predsSinArgmax8[0]\n",
    "            lst_predsSinArgmax8=np.squeeze(lst_predsSinArgmax8)\n",
    "            \n",
    "            \n",
    "            #lst_predsSinArgmax8=lst_predsSinArgmax8[0]\n",
    "\n",
    "            m0 = tf.keras.metrics.MeanIoU(num_classes=num_classes1)\n",
    "            #i=0\n",
    "            #for lst_preds_i in self.lst_preds0: \n",
    "            m0.update_state(test_masksIM8, lst_predsConArgmax8)  \n",
    "            #m0.update_state(test_masksIM[i], self.lst_preds[i]) \n",
    "            #    i+=1\n",
    "            miou0=m0.result().numpy()*100\n",
    "            #print(\"\\x1b[34m\\\"Class Deeplab: MIoU solo de la primera imagen\\\"\\x1b[0m\")\n",
    "            #print(\"MIoU solo de la primera imagen: \",test_images0)\n",
    "            print(\"MIoU de \",str_filename, \" : \",miou0)\n",
    "            \n",
    "            if(\"CRF\"==\"CRF\"):#Siempre se tira CRF\n",
    "                if(boo_activarCRFIn1==True):\n",
    "                    raise Exception(\"Error porque estarias tirando doble CRF uno en este if y otro entrenando deeplab con boo_activarCRFIn=True. Deja boo_activarCRFIn1=False. De hecho tengo que sacar esta opcion representada en la variable boo_activarCRFIn1\")  \n",
    "                    \n",
    "                nda_3DXX3_imgRGB = cv2.cvtColor(cv2.imread(str_DATADIRRAW), cv2.COLOR_BGR2RGB)##Asi esta en A20221210_pipeline5clase. LE estoy pasando al metodo CRF, con metodo CRF no he cargado las imagenes Raw con tensorflow, solo con cv2. Para deeplab si que frecuentemente se leen las imagenes con tensorflow y no con cv2\n",
    "                \n",
    "                nda_3DXX3_imgRGB = cv2.resize(nda_3DXX3_imgRGB, (lst_predsSinArgmax8.shape[0], lst_predsSinArgmax8.shape[1]))#lst_predsSinArgmax8 tiene dimensiones anchox alto x numero de clases\n",
    "                nda_2DXX_imgMask=self.objeto_class_DeepLab.load_dataVBS([str_DATADIRMASK], \n",
    "                                                    mask=True, \n",
    "                                                    to_tensor=False,\n",
    "                                                    img_Size1=int_image_sizeIn1#self.int_IMAGE_SIZE\n",
    "                                                    )[0]\n",
    "                \n",
    "                nda_2DXX_imgMask = np.squeeze(nda_2DXX_imgMask)\n",
    "                \n",
    "                #self.test_masksIM = self.load_dataVBS(lst_test_masks, mask=True, to_tensor=False)\n",
    "                \n",
    "                import import_ipynb\n",
    "                from A20230112_CRF import class_CRF\n",
    "\n",
    "                print(\"lst_predsSinArgmax8.shape: \",lst_predsSinArgmax8.shape)\n",
    "                print(\"np.unique(lst_predsSinArgmax8): \",np.unique(lst_predsSinArgmax8))\n",
    "                \n",
    "                \n",
    "                nda_3DXX2_Q = class_CRF().func_aplicar_CRF(nda_2DXX_sdXIn=-1,\n",
    "                                                 nda_2DXX_sdYIn=-1,\n",
    "                                                 nda_3DXX2_probmapIn=lst_predsSinArgmax8, \n",
    "                                                 tpl_ParametroXYIn=tpl_ParametroXY1, #2 para caballido1 1es el que mas se acerca (1,1) (1,1,1)\n",
    "                                                 tpl_ParametroRGBIn=tpl_ParametroRGB1, #20 para caballito10 1\n",
    "                                                 nda_3DXX3_imgRawIn=nda_3DXX3_imgRGB, \n",
    "                                                 int_inferenceIn=int_inference1, \n",
    "                                                 int_pairwisebilateralCompatIn=int_pairwisebilateralCompat1,\n",
    "                                                 str_PairwiseoKernel=str_PairwiseoKernel1)\n",
    "                print(\"nda_3DXX2_Q.shape: \",nda_3DXX2_Q.shape)\n",
    "                nda_2DXX_ProbCRFmap_Argmax = np.argmax(nda_3DXX2_Q, axis=2)\n",
    "                \n",
    "                from A20230105_MaskImageModel2mIoU import class_MaskImageModel2mIoU\n",
    "                print(\"np.unique(nda_2DXX_imgMask): \", np.unique(nda_2DXX_imgMask))\n",
    "                print(\"(nda_2DXX_imgMask).shape: \", (nda_2DXX_imgMask).shape)\n",
    "                print(\"np.unique(nda_2DXX_ProbCRFmap_Argmax): \", np.unique(nda_2DXX_ProbCRFmap_Argmax))\n",
    "                print(\"(nda_2DXX_ProbCRFmap_Argmax).shape: \", (nda_2DXX_ProbCRFmap_Argmax).shape)\n",
    "                \n",
    "                \n",
    "                flo64_ProbCRFmap_Argmax_miou=class_MaskImageModel2mIoU().calcular_postPrediction_TFmIoU_f7(et_3DXX1_imgMaskIn=nda_2DXX_imgMask, \n",
    "                                                                                                           nda_2DXX_imgTestPredictedIn=nda_2DXX_ProbCRFmap_Argmax, \n",
    "                                                                                                           int_num_classesIn=num_classes1)\n",
    "                print(\"flo64_ProbCRFmap_Argmax_miou \"+\" con CRF \"+str_filename+r\" :\", flo64_ProbCRFmap_Argmax_miou)\n",
    "                \n",
    "                \n",
    "                if (str_dataset2==\"embrion\"):\n",
    "                    self.objeto_class_DeepLab.func_plotearEmbrion(nda_2DXX_ImgIn=nda_2DXX_ProbCRFmap_Argmax,\n",
    "                                                                 str_imgIn=\"Embrion \"+\" con CRF \"+str_filename+\" \",\n",
    "                                                                 flo_miouIn=flo64_ProbCRFmap_Argmax_miou\n",
    "                                                                )\n",
    "                if (str_dataset2==\"neuron\"):\n",
    "                    self.objeto_class_DeepLab.func_plotearEmbrion(nda_2DXX_ImgIn=nda_2DXX_ProbCRFmap_Argmax,#2 clases asi que es lo mismo que usar func_plotearEmbrion\n",
    "                                                                 str_imgIn=\"Neuron \"+\" con CRF \"+str_filename+\" \",\n",
    "                                                                 flo_miouIn=flo64_ProbCRFmap_Argmax_miou\n",
    "                                                                )\n",
    "                if (str_dataset2==\"pascal\"):\n",
    "                    self.objeto_class_DeepLab.func_plotearPascal(nda_2DXX_ImgIn=nda_2DXX_ProbCRFmap_Argmax,\n",
    "                                                                 str_imgIn=\"Caballito \"+\" con CRF \"+ str_filename+\" \",\n",
    "                                                                 flo_miouIn=flo64_ProbCRFmap_Argmax_miou\n",
    "                                                                )\n",
    "\n",
    "\n",
    "                \n",
    "                plt.imshow(nda_2DXX_ProbCRFmap_Argmax)\n",
    "                plt.show()\n",
    "                    \n",
    "                print(tpl_ParametroXY1,\n",
    "                        tpl_ParametroRGB1,                        \n",
    "                        int_pairwisebilateralCompat1,\n",
    "                        int_inference1,\n",
    "                        str_PairwiseoKernel1\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class class_DeepLab_Test_2():#Entrenar modelo\n",
    "    \"\"\"Esta cosa es para agregar bloque de CRF a deeplab al final\"\"\"\n",
    "    def mein(self,\n",
    "            str_dataset2,\n",
    "            str_entrenaroCargar12,\n",
    "            str_dirModelLoad12):\n",
    "            \n",
    "        #str_entrenaroCargar1=\"Train\"\n",
    "        #str_entrenaroCargar1=str_entrenaroCargar12 #20230613\n",
    "        #str_dirModelLoad1=r\"20230119_1932class_DeepLabembrionB3NC2Tra900Val100Tes100Epo100\"\n",
    "        #str_dirModelLoad1=str_dirModelLoad12\n",
    "        boo_guardarModeloIn1=False#20230610    \n",
    "        int_batch_sizeIn1=3#parece que no se puede 4 el monstruito\n",
    "        int_epocasIn1=10000 #Tiene early stopping\n",
    "        #str_dataset=\"embrion\"\n",
    "        #str_dataset=str_dataset2 #20230613\n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "        #if (str_dataset==\"embrion\"):\n",
    "        if (str_dataset2==\"embrion\"):\n",
    "            int_image_sizeIn1=1024#20230613\n",
    "            int_num_classesIn1=2\n",
    "            #data_dirIn1=r\"./COLAB_instance-level-human-parsing2/embryoDataset\"\n",
    "            str_data_dirIn1=r\"COLAB_instance-level-human-parsing2/embryoDataset\" #PascalTrainVal\n",
    "            #data_dirIn1=r\"PascalTrainVal\" #PascalTrainVal\n",
    "            str_mask_folderIn1=r\"EVLstack_SeqDA\" #MasksIgnoreClass21\n",
    "            str_raw_folderIn1=r\"video_animal2_proyeccion_SeqDA2\" #Raws\n",
    "            #raw_folderIn1=r\"Raws\" #Raws\n",
    "            int_num_train_imagesIn1=900\n",
    "            int_num_val_imagesIn1=100\n",
    "            int_num_test_imagesIn1=100 \n",
    "            str_extensionRaw=r\".png\"\n",
    "            num_classes1=2\n",
    "            str_filename=r\"UDF0019\"#una de test\n",
    "            #tpl_ParametroXY1=(1,1)\n",
    "            #tpl_ParametroRGB1=(1,1,1)\n",
    "            #int_pairwisebilateralCompat1=3\n",
    "            #int_inference1=7\n",
    "            #str_PairwiseoKernel1=\"GaussianoSmoothnessKernelYBilateraloAppearanceKernel\"\n",
    "            \n",
    "        if (str_dataset2==\"neuron\"):#Todo este bloque agregado 2024\n",
    "            int_image_sizeIn1=512#20230613 OJO ESTO QUIZAS LO HACE MEJORAR. El original deeplabv3+ es con 512 de size\n",
    "            int_num_classesIn1=2# Con 21 el loss es nan y 0 background\n",
    "            #data_dirIn1=r\"./COLAB_instance-level-human-parsing2/embryoDataset\"\n",
    "            #data_dirIn1=r\"COLAB_instance-level-human-parsing2/embryoDataset\" #PascalTrainVal\n",
    "            str_data_dirIn1=r\"2D_Neuronal_dataset_Proc\" #PascalTrainVal\n",
    "            #raw_folderIn1=r\"video_animal2_proyeccion_SeqDA2\" #Raws\n",
    "            str_mask_folderIn1=r\"Masks\" #MasksIgnoreClass21\n",
    "            str_raw_folderIn1=r\"Raws\" #Raws\n",
    "            #mask_folderIn1=r\"EVLstack_SeqDA\" #MasksIgnoreClass21\n",
    "            int_num_train_imagesIn1=150#1400 Despues considera las de data augmentation\n",
    "            int_num_val_imagesIn1=30#100 Despues considera las de data augmentation\n",
    "            int_num_test_imagesIn1=30#100 Despues considera las de data augmentation\n",
    "            str_extensionRaw=r\".png\"\n",
    "            num_classes1=2\n",
    "            str_filename=r\"1OR0111\"#r\"B2_8_fh\"#una neuronita. TIENE QUE SER DEL CONJUNTO DE TEST... CORRER DEEPLAB CON 1 SOLA EPOCH Y AHI SALEN PRINTEADAS LAS IMAGENES DE CADA CONJUNTO\n",
    "            #tpl_ParametroXY1=(1,1)\n",
    "            #tpl_ParametroRGB1=(1,1,1)\n",
    "            #int_pairwisebilateralCompat1=3\n",
    "            #int_inference1=7\n",
    "            #str_PairwiseoKernel1=\"GaussianoSmoothnessKernelYBilateraloAppearanceKernel\"\n",
    "        \n",
    "\n",
    "            #mask_folderIn1=r\"MasksIgnoreClass21\" #MasksIgnoreClass21\n",
    "        if (str_dataset2==\"pascal\"):  \n",
    "            int_image_sizeIn1=512#20230613 OJO ESTO QUIZAS LO HACE MEJORAR. El original deeplabv3+ es con 512 de size\n",
    "            int_num_classesIn1=22# Con 21 el loss es nan y 0 background\n",
    "            #data_dirIn1=r\"./COLAB_instance-level-human-parsing2/embryoDataset\"\n",
    "            #data_dirIn1=r\"COLAB_instance-level-human-parsing2/embryoDataset\" #PascalTrainVal\n",
    "            str_data_dirIn1=r\"PascalTrainVal\" #PascalTrainVal\n",
    "            #raw_folderIn1=r\"video_animal2_proyeccion_SeqDA2\" #Raws\n",
    "            str_mask_folderIn1=r\"MasksIgnoreClass21\" #MasksIgnoreClass21\n",
    "            str_raw_folderIn1=r\"Raws\" #Raws\n",
    "            #mask_folderIn1=r\"EVLstack_SeqDA\" #MasksIgnoreClass21\n",
    "            int_num_train_imagesIn1=9000\n",
    "            int_num_val_imagesIn1=2000\n",
    "            int_num_test_imagesIn1=1000 \n",
    "            str_extensionRaw=r\".jpg\"\n",
    "            num_classes1=22\n",
    "            str_filename=r\"2011_001253\"#El caballito\n",
    "            #tpl_ParametroXY1=(1,1)\n",
    "            #tpl_ParametroRGB1=(1,1,1)\n",
    "            #int_pairwisebilateralCompat1=3\n",
    "            #int_inference1=7\n",
    "            #str_PairwiseoKernel1=\"GaussianoSmoothnessKernelYBilateraloAppearanceKernel\"\n",
    "\n",
    "\n",
    "        objeto_class_DeepLab=class_DeepLab()\n",
    "        objeto_class_DeepLab(str_entrenaroCargar12,\n",
    "                             str_dirModelLoad12,\n",
    "                             boo_guardarModeloIn1,\n",
    "                             int_image_sizeIn=int_image_sizeIn1, \n",
    "                             int_batch_sizeIn=int_batch_sizeIn1, \n",
    "\n",
    "                             int_num_classesIn=int_num_classesIn1,\n",
    "                             str_data_dirIn=str_data_dirIn1,\n",
    "                             str_mask_folderIn=str_mask_folderIn1,\n",
    "                             str_raw_folderIn=str_raw_folderIn1,                          \n",
    "\n",
    "                             int_num_train_imagesIn=int_num_train_imagesIn1, \n",
    "                             int_num_val_imagesIn=int_num_val_imagesIn1, \n",
    "                             int_num_test_imagesIn=int_num_test_imagesIn1, \n",
    "                             int_epocasIn=int_epocasIn1,\n",
    "                             boo_activarCRFIn=False #O True\n",
    "                            )\n",
    "        \n",
    "        self.objeto_class_DeepLab=objeto_class_DeepLab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class class_DeepLab_Test_3():#Utilizar modelo\n",
    "    \"\"\"\n",
    "    Utilizar modelo de manera simple. Ver que pasaba si predecia una imagen usada en training.. me da valor bajo..que raro\n",
    "    Solo se carga, no se entrena\n",
    "    \"\"\"\n",
    "    def mein(self):\n",
    "        \n",
    "        if(\"ImagenTest\"!=\"ImagenTest\"):\n",
    "            str_imgMaskPathIn9=r\"./COLAB_instance-level-human-parsing2/embryoDataset/EVLstack_SeqDA/UDF0067.png\"#1OR0060, 1OR0079, 1OR0082 da muy buen miou\n",
    "            str_imgRawPathIn9=r\"./COLAB_instance-level-human-parsing2/embryoDataset/video_animal2_proyeccion_SeqDA2/UDF0067.png\"\n",
    "            print(\"Dara esto de miou: 79.85447645187378\")\n",
    "        if(\"ImagenTrain\"==\"ImagenTrain\"):\n",
    "            str_imgMaskPathIn9=r\"./COLAB_instance-level-human-parsing2/embryoDataset/EVLstack_SeqDA/1OR0001.png\"#\n",
    "            str_imgRawPathIn9=r\"./COLAB_instance-level-human-parsing2/embryoDataset/video_animal2_proyeccion_SeqDA2/1OR0001.png\"\n",
    "            print(\"Dara esto de miou: 63.07350397109985\")\n",
    " \n",
    "        ###MASCARA\n",
    "        image = tf.io.read_file(str_imgMaskPathIn9)\n",
    "        image = tf.image.decode_png(image, channels=1)\n",
    "        image.set_shape([None, None, 1])\n",
    "        #image = tf.image.resize(images=image, size=[1024,1024], method=\"nearest\")#20230610\n",
    "\n",
    "        nda_2DXX_imgMask = image.numpy()#(1024, 1024, 1)\n",
    "        nda_2DXX_imgMask = np.squeeze(nda_2DXX_imgMask)\n",
    "        #nda_2DXX_imgMask = nda_2DXX_imgMask.astype(int)\n",
    "        #print(\"nda_2DXX_imgMask.shape: \", nda_2DXX_imgMask.shape)\n",
    "        print(\"np.max(nda_2DXX_imgMask): \", np.max(nda_2DXX_imgMask))\n",
    "        print(\"np.min(nda_2DXX_imgMask): \", np.min(nda_2DXX_imgMask))\n",
    "\n",
    "\n",
    "        ###RAW\n",
    "        image = tf.io.read_file(str_imgRawPathIn9)\n",
    "        image = tf.image.decode_png(image, channels=3)\n",
    "        image.set_shape([None, None, 3])\n",
    "        #image = tf.image.resize(images=image, size=[1024,1024])#20230610\n",
    "\n",
    "        nda_3DXX3_imgRGB = image.numpy()#(1024, 1024, 3)\n",
    "        #nda_3DXX3_imgRGB = nda_3DXX3_imgRGB.astype(int)\n",
    "        #print(\"np.unique(nda_3DXX3_imgRGB): \",np.unique(nda_3DXX3_imgRGB))\n",
    "        #print(\"nda_3DXX3_imgRGB.shape: \", nda_3DXX3_imgRGB.shape)\n",
    "        print(\"np.max(nda_3DXX3_imgRGB): \", np.max(nda_3DXX3_imgRGB))\n",
    "        print(\"np.min(nda_3DXX3_imgRGB): \", np.min(nda_3DXX3_imgRGB))\n",
    "        \n",
    "        str_dirModelLoadIn9=r\"20230709_0917_A20220911_class_DeepLabVBS_DatasetEmbrionBa3NC2Tr105Va10Te30Ep29D0_6Mi75_8\"\n",
    "        Func_model=tf.keras.models.load_model(r\"saved_models/\"+str_dirModelLoadIn9) #20230119_1734\n",
    "        #print(\"type(nda_3DXX3_imgRGB_disc)\", type(nda_3DXX3_imgRGB_disc))\n",
    "        #print(\"(nda_3DXX3_imgRGB_disc).shape\", (nda_3DXX3_imgRGB_disc).shape)\n",
    "\n",
    "        #nda_3DXX3_imgRGB_forPredict = nda_3DXX3_imgRGB_disc / 127.5 - 1#ESTA LINEA ES ABSOLUTAMENTE NECESARIA. ANTES DE PREDECIR SE DEBE NORMALIZAR LA IMAGEN\n",
    "        #nda_3DXX3_imgRGB_forPredict = nda_3DXX3_imgRGB / 127.5#sI PONGO nda_3DXX3_imgRGB, EL PREDICT NO ME TIRA NADA\n",
    "\n",
    "        nda_3DXX2_probmapDL = Func_model.predict(np.expand_dims((nda_3DXX3_imgRGB / 127.5 - 1), axis=0))\n",
    "        nda_3DXX2_probmapDL = np.squeeze(nda_3DXX2_probmapDL)\n",
    "\n",
    "        nda_3DXX2_probmapDL_Argmax = np.argmax(nda_3DXX2_probmapDL, axis=2)\n",
    "\n",
    "        nda_3DXX2_ProbDLmapIn9=nda_3DXX2_probmapDL.copy()#(1024, 1024, 2)\n",
    "        nda_2DXX_ProbDLmap_ArgmaxIn9=nda_3DXX2_probmapDL_Argmax.copy()#(1024, 1024)\n",
    "        \n",
    "        import import_ipynb\n",
    "        from A20230105_MaskImageModel2mIoU import class_MaskImageModel2mIoU\n",
    "        flo64_ProbDLmap_Argmax_miou_Borrame=class_MaskImageModel2mIoU().calcular_postPrediction_TFmIoU_f7(et_3DXX1_imgMaskIn=nda_2DXX_imgMask, \n",
    "                                                                                nda_2DXX_imgTestPredictedIn=nda_2DXX_ProbDLmap_ArgmaxIn9, \n",
    "                                                                                int_num_classesIn=2)\n",
    "        print(\"flo64_ProbDLmap_Argmax_miou CARGANDO MODELO Y HACIENDO TODO SIN CLASE DEEPLAB: \", flo64_ProbDLmap_Argmax_miou_Borrame)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplab str_data_dirIn:  PascalTrainVal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 18:34:30.720228: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-08 18:34:30.740056: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-08 18:34:30.740255: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-08 18:34:30.740732: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-08 18:34:30.742617: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-08 18:34:30.742754: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-08 18:34:30.742873: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-08 18:34:31.134336: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-08 18:34:31.134512: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-08 18:34:31.134638: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-08 18:34:31.134748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22242 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\"Printear Datasets\"\u001b[0m\n",
      "Train Dataset: <BatchDataset element_spec=(TensorSpec(shape=(3, 512, 512, 3), dtype=tf.float32, name=None), TensorSpec(shape=(3, 512, 512, 1), dtype=tf.uint8, name=None))>\n",
      "Val Dataset: <BatchDataset element_spec=(TensorSpec(shape=(3, 512, 512, 3), dtype=tf.float32, name=None), TensorSpec(shape=(3, 512, 512, 1), dtype=tf.uint8, name=None))>\n",
      "Test Dataset: <BatchDataset element_spec=(TensorSpec(shape=(3, 512, 512, 3), dtype=tf.float32, name=None), TensorSpec(shape=(3, 512, 512, 1), dtype=tf.uint8, name=None))>\n",
      "len(train_images) 9000\n",
      "len(val_images) 2000\n",
      "len(test_images) 1000\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "set_common_strings1 Train Val:  set()\n",
      "set_common_strings2 Train Test:  set()\n",
      "set_common_strings3 Val Test:  set()\n",
      "SE METIO A LOAD\n",
      "Modelo a cargar:  20230615_1507_A20220911_class_DeepLabVBS_DatasetPascalBa3NC22Tr9000Va2000Te1000Ep26D1_7Mi52_92\n",
      "Modelo cargado\n",
      "\u001b[34m\"ClassDeeplab: CalcularMioUIndividual\"\u001b[0m\n",
      "Marcador1\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    \n",
    "    #int_Seleccion=\"a\"\n",
    "    int_Seleccion=2#2,4\n",
    "    \n",
    "    if (int_Seleccion==97):\n",
    "        str_dirModelLoad122=r\"?\"\n",
    "        objeto_class_DeepLab_Test=class_DeepLab_Test()\n",
    "        objeto_class_DeepLab_Test.mein(str_dataset2=\"tissue\",\n",
    "                                       str_entrenaroCargar12=\"Train\",#Para entrenar se cambia este por train\n",
    "                                       str_dirModelLoad12=str_dirModelLoad122,\n",
    "                                       boo_activarCRFIn1=False\n",
    "                                      )\n",
    "    \n",
    "    \n",
    "    if (int_Seleccion==98):\n",
    "        str_dirModelLoad122=r\"?\"\n",
    "        objeto_class_DeepLab_Test=class_DeepLab_Test()\n",
    "        objeto_class_DeepLab_Test.mein(str_dataset2=\"neuron\",\n",
    "                                       str_entrenaroCargar12=\"Train\",#Para entrenar se cambia este por train\n",
    "                                       str_dirModelLoad12=str_dirModelLoad122,\n",
    "                                       boo_activarCRFIn1=False\n",
    "                                      )\n",
    "    \n",
    "    if (int_Seleccion==99):\n",
    "        str_dirModelLoad122=r\"20230709_0917_A20220911_class_DeepLabVBS_DatasetEmbrionBa3NC2Tr105Va10Te30Ep29D0_6Mi75_8\"\n",
    "        objeto_class_DeepLab_Test=class_DeepLab_Test()\n",
    "        objeto_class_DeepLab_Test.mein(str_dataset2=\"embrion\",\n",
    "                                       str_entrenaroCargar12=\"Load\",#Para entrenar se cambia este por train\n",
    "                                       str_dirModelLoad12=str_dirModelLoad122,\n",
    "                                       boo_activarCRFIn1=False\n",
    "                                      )\n",
    "    \n",
    "    \n",
    "    if (int_Seleccion==0):\n",
    "        str_dirModelLoad122=r\"20230703_1510_A20220911_class_DeepLabVBS_DatasetNeuronBa3NC2Tr1400Va100Te100Ep44D0_4Mi77_29\"\n",
    "        objeto_class_DeepLab_Test=class_DeepLab_Test()\n",
    "        objeto_class_DeepLab_Test.mein(str_dataset2=\"neuron\",\n",
    "                                       str_entrenaroCargar12=\"Load\",#Para entrenar se cambia este por train\n",
    "                                       str_dirModelLoad12=str_dirModelLoad122,\n",
    "                                       boo_activarCRFIn1=False\n",
    "                                      )\n",
    "    \n",
    "    elif (int_Seleccion==1):\n",
    "        str_dirModelLoad122=r\"20230613_0947_A20220911_class_DeepLabVBS_embryoDatasetMi79_2Ba3NC2Tr900Va100Te100Ep34D0_8\"\n",
    "        objeto_class_DeepLab_Test=class_DeepLab_Test()\n",
    "        objeto_class_DeepLab_Test.mein(str_dataset2=\"embrion\",\n",
    "                                       str_entrenaroCargar12=\"Train\",\n",
    "                                       str_dirModelLoad12=str_dirModelLoad122,\n",
    "                                       boo_activarCRFIn1=False\n",
    "                                      )# se usa UDF0019. UDF0019 (imagen test): 80.00746369361877 con modelo entrenado. 1OR0001(imagen training): \n",
    "        \n",
    "    elif (int_Seleccion==1_2):\n",
    "        str_dirModelLoad122=r\"20230613_0947_A20220911_class_DeepLabVBS_embryoDatasetMi79_2Ba3NC2Tr900Va100Te100Ep34D0_8\"\n",
    "        objeto_class_DeepLab_Test=class_DeepLab_Test()\n",
    "        objeto_class_DeepLab_Test.mein(str_dataset2=\"embrion_sinDA\",\n",
    "                                       str_entrenaroCargar12=\"Load\",\n",
    "                                       str_dirModelLoad12=str_dirModelLoad122,\n",
    "                                       boo_activarCRFIn1=False\n",
    "                                      )\n",
    "    \n",
    "    elif (int_Seleccion==2):\n",
    "        #str_dirModelLoad122=r\"20230613_0221_A20220911_class_DeepLabVBS_PascalTrainValB3NC22Tra9000Val2000Tes1000Epo10000\"\n",
    "        str_dirModelLoad122=r\"20230615_1507_A20220911_class_DeepLabVBS_DatasetPascalBa3NC22Tr9000Va2000Te1000Ep26D1_7Mi52_92\"\n",
    "        objeto_class_DeepLab_Test=class_DeepLab_Test()\n",
    "        objeto_class_DeepLab_Test.mein(str_dataset2=\"pascal\",\n",
    "                                        str_entrenaroCargar12=\"Load\",#Cargó bien embrión con mismos resultados\n",
    "                                        str_dirModelLoad12=str_dirModelLoad122,\n",
    "                                        boo_activarCRFIn1=False\n",
    "                                        )\n",
    "        \n",
    "    #####ESTOS DE ABAJOS SON PARA TESTEAR AGREGANDOLE EL BLOQUE CRF\n",
    "    elif (int_Seleccion==3):\n",
    "        str_dirModelLoad122=r\"20230613_0947_A20220911_class_DeepLabVBS_embryoDatasetMi79_2Ba3NC2Tr900Va100Te100Ep34D0_8\"\n",
    "        objeto_class_DeepLab_Test=class_DeepLab_Test_2()\n",
    "        objeto_class_DeepLab_Test.mein(str_dataset2=\"embrion\",\n",
    "                                       str_entrenaroCargar12=\"Load\",\n",
    "                                       str_dirModelLoad12=str_dirModelLoad122\n",
    "                                      )        \n",
    "    elif (int_Seleccion==5):#Agregado2023\n",
    "        str_dirModelLoad122=r\"20230801_0011_A20220911_class_DeepLabVBS_DatasetNeuronBa3NC2Tr150Va30Te30Ep42D0_3Mi76_01\"\n",
    "        objeto_class_DeepLab_Test=class_DeepLab_Test_2()\n",
    "        objeto_class_DeepLab_Test.mein(str_dataset2=\"neuron\",\n",
    "                                       str_entrenaroCargar12=\"Load\",\n",
    "                                       str_dirModelLoad12=str_dirModelLoad122\n",
    "                                      )\n",
    "    elif (int_Seleccion==4):\n",
    "        str_dirModelLoad122=r\"20230615_1507_A20220911_class_DeepLabVBS_DatasetPascalBa3NC22Tr9000Va2000Te1000Ep26D1_7Mi52_92\"\n",
    "        objeto_class_DeepLab_Test=class_DeepLab_Test_2()\n",
    "        objeto_class_DeepLab_Test.mein(str_dataset2=\"pascal\",\n",
    "                                str_entrenaroCargar12=\"Load\",#Cargó bien embrión con mismos resultados\n",
    "                                str_dirModelLoad12=str_dirModelLoad122\n",
    "                                )\n",
    "        \n",
    "    elif(int_Seleccion==\"a\"):\n",
    "        objeto_class_DeepLab_Test3=class_DeepLab_Test_3()\n",
    "        objeto_class_DeepLab_Test3.mein()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    import numpy as np\n",
    "\n",
    "    my_list = [1, 2, 3, 4, 5]\n",
    "    sample = np.random.choice(my_list, size=3, replace=False)\n",
    "    print(sample)  # Output: a random sample of 3 elements from my_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#objeto_class_DeepLab_Test.objeto_class_DeepLab.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    test_masksIM8=objeto_class_DeepLab_Test.objeto_class_DeepLab.load_dataVBS([r'./COLAB_instance-level-human-parsing2/embryoDataset/EVLstack_SeqDA/UDF0086.png'], \n",
    "                                                                                mask=True, \n",
    "                                                                                to_tensor=False)\n",
    "\n",
    "    lst_predsConArgmax8=objeto_class_DeepLab_Test.objeto_class_DeepLab.calc_predictionsVBSConArgmax([r'./COLAB_instance-level-human-parsing2/embryoDataset/video_animal2_proyeccion_SeqDA2/UDF0086.png'], \n",
    "                                                                                                      objeto_class_DeepLab_Test.objeto_class_DeepLab.model)\n",
    "\n",
    "    #lst_predsSinArgmax8=objeto_class_DeepLab_Test.objeto_class_DeepLab.calc_predictionsVBSSinArgmax([r'./COLAB_instance-level-human-parsing2/embryoDataset/video_animal2_proyeccion_SeqDA2/UDF0085.png'], \n",
    "    #                                                                                                  objeto_class_DeepLab_Test.objeto_class_DeepLab.model)\n",
    "    #lst_predsSinArgmax8=lst_predsSinArgmax8[0]\n",
    "\n",
    "    m0 = tf.keras.metrics.MeanIoU(num_classes=2)\n",
    "    #i=0\n",
    "    #for lst_preds_i in self.lst_preds0: \n",
    "    m0.update_state(test_masksIM8, lst_predsConArgmax8)  \n",
    "        #m0.update_state(test_masksIM[i], self.lst_preds[i]) \n",
    "    #    i+=1\n",
    "    miou0=m0.result().numpy()*100\n",
    "    print(\"\\x1b[34m\\\"Class Deeplab: MIoU solo de la primera imagen\\\"\\x1b[0m\")\n",
    "    #print(\"MIoU solo de la primera imagen: \",test_images0)\n",
    "    print(\"MIoU solo de la primera imagen: \",miou0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lst_predsConArgmax8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    if(\"PrimeraImagenMioU\"==\"PrimeraImagenMioU\"):\n",
    "        self.test_masksIM0 = self.load_dataVBS(test_masks0, mask=True, to_tensor=False, img_Size1=self.int_IMAGE_SIZE)\n",
    "        self.lst_predsConArgmax0=self.calc_predictionsVBSConArgmax(test_images0, self.model) \n",
    "        self.lst_predsSinArgmax0=self.calc_predictionsVBSSinArgmax(test_images0, self.model)#es una lista por eso la modifico abajo     \n",
    "        self.lst_predsSinArgmax0=self.lst_predsSinArgmax0[0]\n",
    "\n",
    "        m0 = tf.keras.metrics.MeanIoU(num_classes=int_num_classesIn)\n",
    "        #i=0\n",
    "        #for lst_preds_i in self.lst_preds0: \n",
    "        m0.update_state(self.test_masksIM0, self.lst_predsConArgmax0)  \n",
    "            #m0.update_state(test_masksIM[i], self.lst_preds[i]) \n",
    "        #    i+=1\n",
    "        self.miou0=m0.result().numpy()*100\n",
    "        print(\"\\x1b[34m\\\"Class Deeplab: MIoU solo de la primera imagen\\\"\\x1b[0m\")\n",
    "        print(\"MIoU solo de la primera imagen: \",test_images0)\n",
    "        print(\"MIoU solo de la primera imagen: \",self.miou0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:    \n",
    "    if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "        str_entrenaroCargar1=\"Train\"\n",
    "        str_dirModelLoad1=r\"20230119_1932class_DeepLabembrionB3NC2Tra900Val100Tes100Epo100\"\n",
    "        boo_guardarModeloIn1=True#20230610    \n",
    "        int_batch_sizeIn1=3#parece que no se puede 4 el monstruito\n",
    "        int_epocasIn1=1#Tiene early stopping\n",
    "        str_dataset=\"embrion\"\n",
    "\n",
    "        if (str_dataset==\"embrion\"):\n",
    "            int_image_sizeIn1=1024#20230613\n",
    "            int_num_classesIn1=2\n",
    "            #data_dirIn1=r\"./COLAB_instance-level-human-parsing2/embryoDataset\"\n",
    "            str_data_dirIn1=r\"COLAB_instance-level-human-parsing2/embryoDataset\" #PascalTrainVal\n",
    "            #data_dirIn1=r\"PascalTrainVal\" #PascalTrainVal\n",
    "            str_mask_folderIn1=r\"EVLstack_SeqDA\" #MasksIgnoreClass21\n",
    "            str_raw_folderIn1=r\"video_animal2_proyeccion_SeqDA2\" #Raws\n",
    "            #raw_folderIn1=r\"Raws\" #Raws\n",
    "            int_num_train_imagesIn1=900\n",
    "            int_num_val_imagesIn1=100\n",
    "            int_num_test_imagesIn1=100 \n",
    "\n",
    "            #mask_folderIn1=r\"MasksIgnoreClass21\" #MasksIgnoreClass21\n",
    "        if (str_dataset==\"pascal\"):  \n",
    "            int_image_sizeIn1=512#20230613\n",
    "            int_num_classesIn1=22# Con 21 el loss es nan y 0 background\n",
    "            #data_dirIn1=r\"./COLAB_instance-level-human-parsing2/embryoDataset\"\n",
    "            #data_dirIn1=r\"COLAB_instance-level-human-parsing2/embryoDataset\" #PascalTrainVal\n",
    "            str_data_dirIn1=r\"PascalTrainVal\" #PascalTrainVal\n",
    "            #raw_folderIn1=r\"video_animal2_proyeccion_SeqDA2\" #Raws\n",
    "            str_mask_folderIn1=r\"MasksIgnoreClass21\" #MasksIgnoreClass21\n",
    "            str_raw_folderIn1=r\"Raws\" #Raws\n",
    "            #mask_folderIn1=r\"EVLstack_SeqDA\" #MasksIgnoreClass21\n",
    "            int_num_train_imagesIn1=9000\n",
    "            int_num_val_imagesIn1=2000\n",
    "            int_num_test_imagesIn1=1000 \n",
    "\n",
    "\n",
    "        objeto_class_DeepLab=class_DeepLab()\n",
    "        objeto_class_DeepLab(str_entrenaroCargar1,\n",
    "                             str_dirModelLoad1,\n",
    "                             boo_guardarModeloIn1,\n",
    "                             int_image_sizeIn=int_image_sizeIn1, \n",
    "                             int_batch_sizeIn=int_batch_sizeIn1, \n",
    "\n",
    "                             int_num_classesIn=int_num_classesIn1,\n",
    "                             str_data_dirIn=str_data_dirIn1,\n",
    "                             str_mask_folderIn=str_mask_folderIn1,\n",
    "                             str_raw_folderIn=str_raw_folderIn1,                          \n",
    "\n",
    "                             int_num_train_imagesIn=int_num_train_imagesIn1, \n",
    "                             int_num_val_imagesIn=int_num_val_imagesIn1, \n",
    "                             int_num_test_imagesIn=int_num_test_imagesIn1, \n",
    "                             int_epocasIn=int_epocasIn1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:    \n",
    "    import os\n",
    "    import glob\n",
    "\n",
    "    str_directory = \"./\"\n",
    "    set_extensions = set()\n",
    "    for file_path in glob.glob(os.path.join(str_directory, \"*\")):\n",
    "        if os.path.isfile(file_path):\n",
    "            file_extension = os.path.splitext(file_path)[1]\n",
    "            set_extensions.add(file_extension)\n",
    "    lst_extensions=list(set_extensions)\n",
    "    lst_extensions[0]\n",
    "    #print(\"File extensions in the directory:\")\n",
    "    #for extension in extensions:\n",
    "    #    print(extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:    \n",
    "    import time\n",
    "\n",
    "    flo_start_time = time.time()\n",
    "\n",
    "    #history = self.model.fit(train_dataset, validation_data=val_dataset, epochs=int_EPOCAS, callbacks=[callback])\n",
    "    time.sleep(3)\n",
    "    flo_end_time = time.time()\n",
    "\n",
    "    flo_duration_seconds = flo_end_time - flo_start_time\n",
    "    flo_duration_hours = flo_duration_seconds / 3600  # Convert seconds to hours\n",
    "\n",
    "    #str_formatted_duration = \"{:.2f} hours\".format(flo_duration_hours)\n",
    "    #str_formatted_duration = round(flo_duration_hours, 1).replace(\".\", \"_\")\n",
    "    flo_rounded_miou = round(flo_duration_hours, 1)\n",
    "    str_rounded_miou = str(flo_rounded_miou).replace(\".\", \"_\")\n",
    "\n",
    "    print(\"Training duration:\", str_rounded_miou)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: #Usar este en el futuro si es que se quieren tener sets random (no sorted) de training, validation y test    \n",
    "    import os\n",
    "    import random\n",
    "\n",
    "    mask_folder = r\"embryoDataset_SinDA/EVLstack_Seq\"\n",
    "    raw_folder = r\"embryoDataset_SinDA/video_animal2_proyeccion_Seq\"\n",
    "\n",
    "    test_ratio = 0.2  # Percentage of files for the test set\n",
    "    validation_ratio = 0.1  # Percentage of files for the validation set\n",
    "\n",
    "    seed = 123  # Seed value for reproducibility\n",
    "\n",
    "    # Set the seed value\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Get the list of file names in the raw folder\n",
    "    file_names = os.listdir(raw_folder)\n",
    "\n",
    "    # Shuffle the file names randomly\n",
    "    random.shuffle(file_names)\n",
    "\n",
    "    # Calculate the number of files for each set\n",
    "    total_files = len(file_names)\n",
    "    test_count = int(total_files * test_ratio)\n",
    "    validation_count = int(total_files * validation_ratio)\n",
    "    training_count = total_files - test_count - validation_count\n",
    "\n",
    "    # Split the file names into sets\n",
    "    test_set = random.sample(file_names, test_count)\n",
    "    validation_set = random.sample(set(file_names) - set(test_set), validation_count)\n",
    "    training_set = list(set(file_names) - set(test_set) - set(validation_set))\n",
    "\n",
    "    # Create the full file paths for each set\n",
    "    test_set_files = [(os.path.join(raw_folder, file), os.path.join(mask_folder, file)) for file in test_set]\n",
    "    validation_set_files = [(os.path.join(raw_folder, file), os.path.join(mask_folder, file)) for file in validation_set]\n",
    "    training_set_files = [(os.path.join(raw_folder, file), os.path.join(mask_folder, file)) for file in training_set]\n",
    "\n",
    "    # Print the file lists\n",
    "    print(\"Test Set:\")\n",
    "    print(test_set_files)\n",
    "    print(\"Validation Set:\")\n",
    "    print(validation_set_files)\n",
    "    print(\"Training Set:\")\n",
    "    print(training_set_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:    \n",
    "    import os\n",
    "    import random\n",
    "\n",
    "    mask_folder = r\"embryoDataset_SinDA/EVLstack_Seq\"\n",
    "    raw_folder = r\"embryoDataset_SinDA/video_animal2_proyeccion_Seq\"\n",
    "\n",
    "    test_ratio = 0.2  # Percentage of files for the test set\n",
    "    validation_ratio = 0.1  # Percentage of files for the validation set\n",
    "\n",
    "    seed = 123  # Seed value for reproducibility\n",
    "\n",
    "    # Set the seed value\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Get the list of file names in the raw folder\n",
    "    file_names = os.listdir(raw_folder)\n",
    "\n",
    "    # Shuffle the file names randomly\n",
    "    random.shuffle(file_names)\n",
    "\n",
    "    # Calculate the number of files for each set\n",
    "    total_files = len(file_names)\n",
    "    training_count = int(total_files * (1 - test_ratio - validation_ratio))\n",
    "    validation_count = int(total_files * validation_ratio)\n",
    "    test_count = total_files - training_count - validation_count\n",
    "\n",
    "    # Split the file names into sets\n",
    "    training_set = file_names[:training_count]\n",
    "    validation_set = file_names[training_count:training_count + validation_count]\n",
    "    test_set = file_names[training_count + validation_count:]\n",
    "\n",
    "    # Create the full file paths for each set\n",
    "    training_set_files_Masks = [os.path.join(mask_folder, file) for file in training_set]\n",
    "    training_set_files_Raws = [os.path.join(raw_folder, file) for file in training_set]\n",
    "\n",
    "\n",
    "    validation_set_files_Masks = [os.path.join(mask_folder, file) for file in validation_set]\n",
    "    validation_set_files_Raws = [os.path.join(raw_folder, file) for file in validation_set]\n",
    "\n",
    "    test_set_files_Masks = [os.path.join(mask_folder, file) for file in test_set]\n",
    "    test_set_files_Raws = [os.path.join(raw_folder, file) for file in test_set]\n",
    "\n",
    "\n",
    "    #validation_set_files = [(os.path.join(raw_folder, file), os.path.join(mask_folder, file)) for file in validation_set]\n",
    "    #test_set_files = [(os.path.join(raw_folder, file), os.path.join(mask_folder, file)) for file in test_set]\n",
    "\n",
    "    # Print the file lists\n",
    "    print(\"Training Set:\")\n",
    "    for training_set_files_Masks_i in training_set_files_Masks:\n",
    "        print(training_set_files_Masks_i)\n",
    "    #print(training_set_files)\n",
    "    print(\"Validation Set:\")\n",
    "    for validation_set_files_Masks_i in validation_set_files_Masks:\n",
    "        print(validation_set_files_Masks_i)\n",
    "    #print(validation_set_files)\n",
    "    print(\"Test Set:\")\n",
    "    for test_set_files_Masks_i in test_set_files_Masks:\n",
    "        print(test_set_files_Masks_i)\n",
    "    #print(test_set_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    import os\n",
    "\n",
    "    def get_filenames(file_paths):\n",
    "        return [os.path.splitext(os.path.basename(path))[0] for path in file_paths]\n",
    "\n",
    "    def compare_filename_lists(list1, list2):\n",
    "        filenames1 = set(get_filenames(list1))\n",
    "        filenames2 = set(get_filenames(list2))\n",
    "\n",
    "        common_filenames = filenames1.intersection(filenames2)\n",
    "\n",
    "        return common_filenames\n",
    "\n",
    "    # Example usage\n",
    "    list1 = training_set_files_Masks\n",
    "    list2 = training_set_files_Raws\n",
    "\n",
    "    common_filenames = compare_filename_lists(list1, list2)\n",
    "    print(common_filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:    \n",
    "    import os\n",
    "\n",
    "    def func_MismosFilenames(\n",
    "                             lst_setMasksIn, \n",
    "                             lst_setRawsIn): \n",
    "\n",
    "        def get_filenames(lst_str_file_paths):\n",
    "            return {os.path.splitext(os.path.basename(str_path))[0] for str_path in lst_str_file_paths}\n",
    "\n",
    "        def compare_filename_lists(lst_str_list1, lst_str_list2):\n",
    "            set_str_filenames1 = get_filenames(lst_str_list1)\n",
    "            set_str_filenames2 = get_filenames(lst_str_list2)\n",
    "\n",
    "            set_str_common_filenames = set_str_filenames1.intersection(set_str_filenames2)\n",
    "            if (len(set_str_common_filenames) > 0):\n",
    "                pass\n",
    "            return (len(set_str_common_filenames) > 0)\n",
    "\n",
    "        # Example usage\n",
    "        #list1 = training_set_files_Masks\n",
    "        #list2 = validation_set_files_Raws\n",
    "\n",
    "        boo_have_same_filenames = compare_filename_lists(lst_setMasksIn, lst_setRawsIn)\n",
    "        #print(boo_have_same_filenames)\n",
    "        return(boo_have_same_filenames)\n",
    "\n",
    "    boo_SetsTes = func_MismosFilenames(lst_test_set_Masks, lst_validation_set_Raws)#lst_test_set_Raws\n",
    "\n",
    "    if False:\n",
    "        boo_SetsVal = func_MismosFilenames(lst_validation_set_Masks, lst_validation_set_Raws)\n",
    "        boo_SetsTra = func_MismosFilenames(lst_training_set_Masks, lst_training_set_Raws)\n",
    "\n",
    "        if((boo_SetsTra!=True) or (boo_SetsVal!=True) or (boo_SetsTes!=True)):\n",
    "            raise Exception(\"No coinciden los archivos representados en las listas:\"+\n",
    "                            \"training_set_files_Masks, training_set_files_Raws\"+\n",
    "                            \"validation_set_files_Masks, validation_set_files_Raws\"+\n",
    "                            \"test_set_files_Masks, test_set_files_Raws\"\n",
    "                           )  \n",
    "        else:\n",
    "            print(\"Los datasets Masks y Raws de Training, Validation y Test coinciden\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{os.path.splitext(os.path.basename(str_path))[0] for str_path in lst_test_set_Masks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{os.path.splitext(os.path.basename(str_path))[0] for str_path in lst_validation_set_Raws}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lst_validation_set_Raws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:    \n",
    "    def compare_filename_lists(list1, list2):\n",
    "        filenames1 = {os.path.splitext(os.path.basename(file1))[0] for file1 in list1}\n",
    "        filenames2 = {os.path.splitext(os.path.basename(file2))[0] for file2 in list2}\n",
    "\n",
    "        return filenames1 == filenames2\n",
    "\n",
    "\n",
    "    have_same_filenames = compare_filename_lists(lst_test_set_Masks, lst_test_set_Raws)\n",
    "    #have_same_filenames = compare_filename_lists(lst_validation_set_Masks, lst_validation_set_Raws)\n",
    "    #have_same_filenames = compare_filename_lists(lst_training_set_Masks, lst_training_set_Raws)\n",
    "\n",
    "    print(have_same_filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lst_test_set_Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lst_test_set_Raws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:    \n",
    "    def func_NoDebenIntersectar(list1, list2):\n",
    "        filenames1 = set(os.path.splitext(os.path.basename(file1))[0] for file1 in list1)\n",
    "        filenames2 = set(os.path.splitext(os.path.basename(file2))[0] for file2 in list2)\n",
    "\n",
    "        common_filenames = filenames1.intersection(filenames2)#Se intersectan si o no?\n",
    "        if (len(common_filenames)>0):\n",
    "            print(\"Se intersectan\")\n",
    "        else:\n",
    "            print(\"No see intersectan\")\n",
    "\n",
    "        return (len(common_filenames) > 0)\n",
    "\n",
    "    boo_SetsTes = compare_filename_lists(lst_test_set_Masks, lst_validation_set_Raws)\n",
    "    boo_SetsVal = compare_filename_lists(lst_validation_set_Masks, lst_validation_set_Raws)\n",
    "    boo_SetsTra = compare_filename_lists(lst_training_set_Masks, lst_training_set_Raws)\n",
    "\n",
    "\n",
    "    if((boo_SetsTra!=True) or (boo_SetsVal!=True) or (boo_SetsTes!=True)):\n",
    "        raise Exception(\"No coinciden los archivos representados en las listas:\"+\n",
    "                        \"training_set_files_Masks, training_set_files_Raws\"+\n",
    "                        \"validation_set_files_Masks, validation_set_files_Raws\"+\n",
    "                        \"test_set_files_Masks, test_set_files_Raws\"\n",
    "                       )  \n",
    "    else:\n",
    "        print(\"Los datasets Masks y Raws de Training, Validation y Test coinciden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    filenames1 = set(os.path.splitext(os.path.basename(file1))[0] for file1 in lst_validation_set_Raws)\n",
    "    filenames2 = set(os.path.splitext(os.path.basename(file2))[0] for file2 in lst_test_set_Raws)\n",
    "\n",
    "    common_filenames = filenames1.intersection(filenames2)#Se intersectan si o no?\n",
    "    common_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(lst_str_file_names_Raws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(lst_str_file_names_Path_Masks)\n",
    "#lst_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lst_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lst_test_set_Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    print(\"oficial\")\n",
    "    def func_comprobarNoTraslape_TrainValTest(lst_str_filenamePath_testSet_MasksIn, lst_str_filenamePath_validationSet_MasksIn, lst_str_filenamePath_trainingSet_MasksIn,\n",
    "                                              lst_str_filenamePath_testSet_RawsIn, lst_str_filenamePath_validationSet_RawsIn, lst_str_filenamePath_trainingSet_RawsIn\n",
    "                                              ):\n",
    "\n",
    "        # Check if there are no intersections between list1 and list2\n",
    "        boo_intersectionsMasks_12 = len(set(lst_str_filenamePath_testSet_MasksIn).intersection(set(lst_str_filenamePath_validationSet_MasksIn))) > 0\n",
    "\n",
    "        # Check if there are no intersections between list1 and list3\n",
    "        boo_intersectionsMasks_13 = len(set(lst_str_filenamePath_testSet_MasksIn).intersection(set(lst_str_filenamePath_trainingSet_MasksIn))) > 0\n",
    "\n",
    "        # Check if there are no intersections between list2 and list3\n",
    "        boo_intersectionsMasks_23 = len(set(lst_str_filenamePath_validationSet_MasksIn).intersection(set(lst_str_filenamePath_trainingSet_MasksIn))) > 0\n",
    "\n",
    "        # Check if there are no intersections between all three lists\n",
    "        boo_intersectionsMasks_all = boo_intersectionsMasks_12 or boo_intersectionsMasks_13 or boo_intersectionsMasks_23\n",
    "\n",
    "        # Check if there are no intersections between list1 and list2\n",
    "        boo_intersectionsRaws_12 = len(set(lst_str_filenamePath_testSet_RawsIn).intersection(set(lst_str_filenamePath_validationSet_RawsIn))) > 0\n",
    "\n",
    "        # Check if there are no intersections between list1 and list3\n",
    "        boo_intersectionsRaws_13 = len(set(lst_str_filenamePath_testSet_RawsIn).intersection(set(lst_str_filenamePath_trainingSet_RawsIn))) > 0\n",
    "\n",
    "        # Check if there are no intersections between list2 and list3\n",
    "        boo_intersectionsRaws_23 = len(set(lst_str_filenamePath_validationSet_RawsIn).intersection(set(lst_str_filenamePath_trainingSet_RawsIn))) > 0\n",
    "\n",
    "        # Check if there are no intersections between all three lists\n",
    "        boo_intersectionsRaws_all = boo_intersectionsRaws_12 or boo_intersectionsRaws_13 or boo_intersectionsRaws_23\n",
    "\n",
    "        print(r\"Intersections between MASKS list1 and list2 ?:\", boo_intersectionsMasks_12)\n",
    "        print(r\"Intersections between MASKS list1 and list3 ?:\", boo_intersectionsMasks_13)\n",
    "        print(r\"Intersections between MASKS list2 and list3 ?:\", boo_intersectionsMasks_23)\n",
    "        print(r\"Intersections between MASKS all three lists ?:\", boo_intersectionsMasks_all)\n",
    "\n",
    "        print(r\"Intersections between RAWS list1 and list2 ?:\", boo_intersectionsRaws_12)\n",
    "        print(r\"Intersections between RAWS list1 and list3 ?:\", boo_intersectionsRaws_13)\n",
    "        print(r\"Intersections between RAWS list2 and list3 ?:\", boo_intersectionsRaws_23)\n",
    "        print(r\"Intersections between RAWS all three lists ?:\", boo_intersectionsRaws_all)\n",
    "\n",
    "        if(boo_intersectionsMasks_all!=False or boo_intersectionsRaws_all!=False):\n",
    "            raise Exception(\"Por lo menos uno de los conjuntos de TrainValTest se traslapa\")\n",
    "        return(\"OK. TrainValTest no se traslapan\")\n",
    "\n",
    "    func_comprobarNoTraslape_TrainValTest(lst_str_filenamePath_testSet_Masks, lst_str_filenamePath_validationSet_Masks, lst_str_filenamePath_trainingSet_Masks,\n",
    "                                          lst_str_filenamePath_testSet_Raws, lst_str_filenamePath_validationSet_Raws, lst_str_filenamePath_trainingSet_Raws\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    print(\"oficial\")\n",
    "    def func_comprobarMaskyRawsiguales_TrainValTest(lst_str_filenamePath_testSet_MasksIn, lst_str_filenamePath_testSet_RawsIn,\n",
    "                                                    lst_str_filenamePath_validationSet_MasksIn, lst_str_filenamePath_validationSet_RawsIn,\n",
    "                                                    lst_str_filenamePath_trainingSet_MasksIn, lst_str_filenamePath_trainingSet_RawsIn,\n",
    "                                                   ):\n",
    "\n",
    "        def func_DirectoriosTienenMismosArchivos(list1, list2):\n",
    "            filenames1 = {os.path.splitext(os.path.basename(file1))[0] for file1 in list1}\n",
    "            filenames2 = {os.path.splitext(os.path.basename(file2))[0] for file2 in list2}\n",
    "            boo_SonIguales = filenames1 == filenames2\n",
    "            return (boo_SonIguales)\n",
    "\n",
    "        boo_test_MasksRaws = func_DirectoriosTienenMismosArchivos(lst_str_filenamePath_testSet_MasksIn, lst_str_filenamePath_testSet_RawsIn)#lst_str_filenamePath_testSet_Raws\n",
    "        boo_validation_MasksRaws = func_DirectoriosTienenMismosArchivos(lst_str_filenamePath_validationSet_MasksIn, lst_str_filenamePath_validationSet_RawsIn)\n",
    "        boo_training_MasksRaws = func_DirectoriosTienenMismosArchivos(lst_str_filenamePath_trainingSet_MasksIn, lst_str_filenamePath_trainingSet_RawsIn)\n",
    "\n",
    "        if(boo_test_MasksRaws!=True or boo_validation_MasksRaws!=True or boo_training_MasksRaws!=True):\n",
    "            raise Exception(\"No tienen los mismos filepaths los conjuntos de MaskyRaw de alguno de los conjuntos de train, val o test\")\n",
    "\n",
    "        return(\"OK. MaskyRaw tienen los mismos archivos para TrainValTest\")\n",
    "        #print(boo_test_MasksRaws)\n",
    "\n",
    "    func_comprobarMaskyRawsiguales_TrainValTest(lst_str_filenamePath_testSet_Masks, lst_str_filenamePath_testSet_Raws,\n",
    "                                                lst_str_filenamePath_validationSet_Masks, lst_str_filenamePath_validationSet_Raws,\n",
    "                                                lst_str_filenamePath_trainingSet_Masks, lst_str_filenamePath_trainingSet_Raws\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    print(\"oficial\")\n",
    "    import os\n",
    "    import random\n",
    "    from glob import glob\n",
    "\n",
    "    str_mask_folder = r\"COLAB_instance-level-human-parsing2/embryoDataset/EVLstack_SeqDA\"\n",
    "    str_raw_folder = r\"COLAB_instance-level-human-parsing2/embryoDataset/video_animal2_proyeccion_SeqDA2\"\n",
    "\n",
    "    #have_same_filenames = func_DirectoriosTienenMismosArchivos(lst_str_file_names_Masks, lst_str_file_names_Raws)\n",
    "    #if (have_same_filenames!=True):\n",
    "    #    raise Exception(\"No tienen los mismos nombres de archivo las carpetas\")\n",
    "\n",
    "    int_testFilescount=30#Numeros sin considerar data augmentation\n",
    "    int_validationFilescount=10#Numeros sin considerar data augmentation\n",
    "    int_trainingFilescount=105#Numeros sin considerar data augmentation. Este se va a multpilicar por 8 con DA\n",
    "\n",
    "\n",
    "\n",
    "    if(\"datasetembrion\"==\"datasetembrion\"):#Esto es para sacar a los data augmented de test y validation\n",
    "        if (int_testFilescount+int_validationFilescount+int_trainingFilescount>145):\n",
    "            raise Exception(\"Hay solo 145 imagenes, hay que achicar int_testFilescount o int_validationFilescount o int_trainingFilescount\")\n",
    "\n",
    "        seed = 123 \n",
    "        random.seed(seed)\n",
    "\n",
    "        lst_str_filenamePath_10R_Masks = glob(os.path.join(str_mask_folder, \"1OR*\"))\n",
    "        lst_str_filenamePath_10R_Raws = glob(os.path.join(str_raw_folder, \"1OR*\"))\n",
    "\n",
    "        lst_str_filenamePath_Masks = glob(str_mask_folder + '/*')\n",
    "        lst_str_filenamePath_Raws = glob(str_raw_folder + '/*')\n",
    "\n",
    "        #Test\n",
    "        lst_str_filenamePath_10R_testSet = np.random.sample(set(lst_str_filenamePath_10R_Masks), int_testFilescount)#Selecciono solo de entre 1OR que es la imagen sin ninguna rotacion\n",
    "        lst_str_filename_10R_testSet = [os.path.splitext(os.path.basename(path))[0] for path in lst_str_filenamePath_10R_testSet]#Me quedo con los filenames. Ejemplo: 1OR0027\n",
    "        lst_str_filenamePath_10R_testSet_Masks = [path for path in lst_str_filenamePath_Masks if os.path.splitext(os.path.basename(path))[0] in lst_str_filename_10R_testSet]#Recupero el path a partir de los filenames para Mask\n",
    "        lst_str_filenamePath_10R_testSet_Raws = [path for path in lst_str_filenamePath_Raws if os.path.splitext(os.path.basename(path))[0] in lst_str_filename_10R_testSet]#Recupero el path a partir de los filenames para Raws\n",
    "\n",
    "        #Validation\n",
    "        lst_str_filenamePath_10R_validationSet = np.random.sample(set(lst_str_filenamePath_10R_Masks)-set(lst_str_filenamePath_10R_testSet_Masks), int_validationFilescount)#Selecciono solo de entre 1OR que es la imagen sin ninguna rotacion\n",
    "        lst_str_filename_10R_validationSet = [os.path.splitext(os.path.basename(path))[0] for path in lst_str_filenamePath_10R_validationSet]#Me quedo con los filenames    \n",
    "        lst_str_filenamePath_10R_validationSet_Masks = [path for path in lst_str_filenamePath_Masks if os.path.splitext(os.path.basename(path))[0] in lst_str_filename_10R_validationSet]\n",
    "        lst_str_filenamePath_10R_validationSet_Raws = [path for path in lst_str_filenamePath_Raws if os.path.splitext(os.path.basename(path))[0] in lst_str_filename_10R_validationSet]\n",
    "\n",
    "        #Training\n",
    "        lst_str_filenamePath_10R_trainingSet = np.random.sample(set(lst_str_filenamePath_10R_Masks)-set(lst_str_filenamePath_10R_testSet_Masks)-set(lst_str_filenamePath_10R_validationSet_Masks), int_trainingFilescount) #Selecciono solo de entre 1OR que es la imagen sin ninguna rotacion\n",
    "        lst_str_filename_10R_trainingSet = [os.path.splitext(file)[0][-4:]  for file in lst_str_filenamePath_10R_trainingSet] # Me quedo solo con el nombre del archivo sin prefijos ni sufijos y con extensión\n",
    "        lst_str_filenamePath_10R_trainingSet_Masks = [file_path for file_path in lst_str_filenamePath_Masks if any(substr in file_path for substr in lst_str_filename_10R_trainingSet)]\n",
    "        lst_str_filenamePath_10R_trainingSet_Raws = [file_path for file_path in lst_str_filenamePath_Raws if any(substr in file_path for substr in lst_str_filename_10R_trainingSet)]\n",
    "\n",
    "\n",
    "        lst_str_filenamePath_testSet_Masks=lst_str_filenamePath_10R_testSet_Masks\n",
    "        lst_str_filenamePath_testSet_Raws=lst_str_filenamePath_10R_testSet_Raws\n",
    "        lst_str_filenamePath_validationSet_Masks=lst_str_filenamePath_10R_validationSet_Masks\n",
    "        lst_str_filenamePath_validationSet_Raws=lst_str_filenamePath_10R_validationSet_Raws\n",
    "        lst_str_filenamePath_trainingSet_Masks=lst_str_filenamePath_10R_trainingSet_Masks\n",
    "        lst_str_filenamePath_trainingSet_Raws=lst_str_filenamePath_10R_trainingSet_Raws\n",
    "\n",
    "\n",
    "\n",
    "    #print(len(lst_training_set_Masks))\n",
    "    #print(len(lst_validation_set_Masks))\n",
    "    #print(len(lst_test_set_Masks))\n",
    "\n",
    "    #print(145*8-840-10*8-30*8)\n",
    "    print(\"len(lst_str_filenamePath_testSet_Masks)\", len(lst_str_filenamePath_testSet_Masks))\n",
    "    print(\"len(lst_str_filenamePath_validationSet_Masks)\", len(lst_str_filenamePath_validationSet_Masks))\n",
    "    print(\"len(lst_str_filenamePath_trainingSet_Masks)\", len(lst_str_filenamePath_trainingSet_Masks))\n",
    "\n",
    "    print(\"len(lst_str_filenamePath_testSet_Raws)\", len(lst_str_filenamePath_testSet_Raws))\n",
    "    print(\"len(lst_str_filenamePath_validationSet_Raws)\", len(lst_str_filenamePath_validationSet_Raws))\n",
    "    print(\"len(lst_str_filenamePath_trainingSet_Raws)\", len(lst_str_filenamePath_trainingSet_Raws))\n",
    "\n",
    "    if True:\n",
    "\n",
    "        # Print the file lists\n",
    "        print(\"Test Set MASK:\")\n",
    "        for lst_str_filenamePath_testSet_Masks_i in lst_str_filenamePath_testSet_Masks:\n",
    "            print(lst_str_filenamePath_testSet_Masks_i)\n",
    "        print(\"Validation Set MASK:\")\n",
    "        for lst_str_filenamePath_validationSet_Masks_i in lst_str_filenamePath_validationSet_Masks:\n",
    "            print(lst_str_filenamePath_validationSet_Masks_i)\n",
    "        print(\"Training Set MASK:\")\n",
    "        for lst_str_filenamePath_trainingSet_Masks_i in lst_str_filenamePath_trainingSet_Masks:\n",
    "            print(lst_str_filenamePath_trainingSet_Masks_i)\n",
    "\n",
    "        print(\"Test Set RAWS:\")\n",
    "        for lst_str_filenamePath_testSet_Raws_i in lst_str_filenamePath_testSet_Raws:\n",
    "            print(lst_str_filenamePath_testSet_Raws_i)\n",
    "        print(\"Validation Set RAWS:\")\n",
    "        for lst_str_filenamePath_validationSet_Raws_i in lst_str_filenamePath_validationSet_Raws:\n",
    "            print(lst_str_filenamePath_validationSet_Raws_i)\n",
    "        print(\"Training Set RAWS:\")\n",
    "        for lst_str_filenamePath_trainingSet_Raws_i in lst_str_filenamePath_trainingSet_Raws:\n",
    "            print(lst_str_filenamePath_trainingSet_Raws_i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:    \n",
    "    import os\n",
    "    import random\n",
    "\n",
    "    mask_folder = r\"embryoDataset_SinDA/EVLstack_Seq\"\n",
    "    raw_folder = r\"embryoDataset_SinDA/video_animal2_proyeccion_Seq\"\n",
    "\n",
    "    test_ratio = 0.2  # Percentage of files for the test set\n",
    "    validation_ratio = 0.1  # Percentage of files for the validation set\n",
    "\n",
    "    seed = 123  # Seed value for reproducibility\n",
    "\n",
    "    # Set the seed value\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Get the list of file names in the raw folder\n",
    "    file_names = os.listdir(raw_folder)\n",
    "\n",
    "    # Keep only the last four characters (excluding extension) in the file names\n",
    "    file_names = [os.path.splitext(file)[0][-4:] + os.path.splitext(file)[1] for file in file_names]\n",
    "\n",
    "    # Calculate the number of files for each set\n",
    "    total_files = len(file_names)\n",
    "    test_count = int(total_files * test_ratio)\n",
    "    validation_count = int(total_files * validation_ratio)\n",
    "    training_count = total_files - test_count - validation_count\n",
    "\n",
    "    # Split the file names into sets\n",
    "    test_set = random.sample(file_names, test_count)\n",
    "    validation_set = random.sample(set(file_names) - set(test_set), validation_count)\n",
    "    training_set = list(set(file_names) - set(test_set) - set(validation_set))\n",
    "\n",
    "    # Create the full file paths for each set\n",
    "    test_set_files_Masks = [os.path.join(mask_folder, file) for file in test_set]\n",
    "    test_set_files_Raws = [os.path.join(raw_folder, file) for file in test_set]\n",
    "\n",
    "    validation_set_files_Masks = [os.path.join(mask_folder, file) for file in validation_set]\n",
    "    validation_set_files_Raws = [os.path.join(raw_folder, file) for file in validation_set]\n",
    "\n",
    "    training_set_files_Masks = [os.path.join(mask_folder, file) for file in file_names if any(filename in file for filename in training_set)]\n",
    "    training_set_files_Raws = [os.path.join(raw_folder, file) for file in file_names if any(filename in file for filename in training_set)]\n",
    "\n",
    "    # Print the file lists\n",
    "    print(\"Test Set:\")\n",
    "    for test_set_files_Masks_i in test_set_files_Masks:\n",
    "        print(test_set_files_Masks_i)\n",
    "    print(\"Validation Set:\")\n",
    "    for validation_set_files_Masks_i in validation_set_files_Masks:\n",
    "        print(validation_set_files_Masks_i)\n",
    "    print(\"Training Set:\")\n",
    "    for training_set_files_Masks_i in training_set_files_Masks:\n",
    "        print(training_set_files_Masks_i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(formatted_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.imread(r\"./COLAB_instance-level-human-parsing2/embryoDataset/video_animal2_proyeccion_SeqDA/UDF0085.jpg\", cv2.COLOR_BGR2RGB).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.imread(r\"./COLAB_instance-level-human-parsing2/embryoDataset/EVLstack_SeqDA/UDF0085.png\", cv2.COLOR_BGR2RGB).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:    \n",
    "    #if __name__ == \"__main__\": \n",
    "    import os\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "    import import_ipynb\n",
    "    from A20230530_TransformarImagenes import class_TransformarImagen as CTI\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "    str_dirModelLoadIn9=r\"20230709_0917_A20220911_class_DeepLabVBS_DatasetEmbrionBa3NC2Tr105Va10Te30Ep29D0_6Mi75_8\"\n",
    "\n",
    "    str_imgMaskPathIn9=r\"./COLAB_instance-level-human-parsing2/embryoDataset/EVLstack_SeqDA/1OR0000.png\"\n",
    "    str_imgRawPathIn9=r\"./COLAB_instance-level-human-parsing2/embryoDataset/video_animal2_proyeccion_SeqDA2/1OR0000.png\"\n",
    "\n",
    "    #MASK\n",
    "    image = tf.io.read_file(str_imgMaskPathIn9)\n",
    "    image = tf.image.decode_png(image, channels=1)\n",
    "    image.set_shape([None, None, 1])\n",
    "    image = tf.cast(image, tf.float32) \n",
    "    #image = tf.image.resize(images=image, size=[1024,1024], method=\"nearest\")#20230610\n",
    "\n",
    "    nda_2DXX_uint8_imgMask = image.numpy()#(1024, 1024, 1)\n",
    "    nda_2DXX_uint8_imgMask = np.squeeze(nda_2DXX_uint8_imgMask)\n",
    "\n",
    "    #RAW\n",
    "    image = tf.io.read_file(str_imgRawPathIn9)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    image.set_shape([None, None, 3])\n",
    "    nda_3DXX3_uint8_imgRGB = image.numpy()\n",
    "    #image = tf.image.resize(images=image, size=[1024,1024])#20230610\n",
    "\n",
    "\n",
    "    int_valorDiscontinuidadIn_Raw=0\n",
    "    str_franjaColor_Raw=\"unicolor_interseccion\"\n",
    "    lst_int_ColDisc1=None\n",
    "    int_ColGrosor1=None\n",
    "    lst_int_RowDisc1=[50]\n",
    "    int_RowGrosor1=10\n",
    "\n",
    "\n",
    "    nda_3DXX3_uint8_imgRGB_disc=CTI.func_deteriorarImagenDiscontinuidades(nda_2DXXo3DXX3_imgIn=nda_3DXX3_uint8_imgRGB, #20230616\n",
    "                                                                                                        lst_int_RowDisc=lst_int_RowDisc1,\n",
    "                                                                                                        int_RowGrosor=int_RowGrosor1,\n",
    "                                                                                                        lst_int_ColDisc=None,\n",
    "                                                                                                        int_ColGrosor=None,\n",
    "                                                                                                        int_valorDiscontinuidadIn=int_valorDiscontinuidadIn_Raw,#None,\n",
    "                                                                                                        #boo_normalizar0_255=True,\n",
    "                                                                                                        #str_franjaColor=\"azarEntre_127_128_paraRGB_interseccion\",\n",
    "                                                                                                        str_franjaColor=str_franjaColor_Raw,#Para deeplab\n",
    "                                                                                                        nda_2DXX_imgMaskIn=nda_2DXX_uint8_imgMask\n",
    "                                                                                                        #nda_2DXX_imgMaskIn=None\n",
    "                                                                                            )\n",
    "    plt.imshow(nda_3DXX3_uint8_imgRGB_disc)\n",
    "    plt.show()\n",
    "\n",
    "    print(\"adass\")\n",
    "\n",
    "    Func_model=tf.keras.models.load_model(r\"saved_models/20230709_0917_A20220911_class_DeepLabVBS_DatasetEmbrionBa3NC2Tr105Va10Te30Ep29D0_6Mi75_8\")\n",
    "    #Func_model=tf.keras.models.load_model(r\"saved_models/\"+str_dirModelLoadIn9) #20230119_1734\n",
    "    print(\"adass2\")\n",
    "    #Func_model.predict(np.expand_dims(nda_3DXX3_uint8_imgRGB_disc, axis=0))#Loagregue 20290929\n",
    "    print(\"nda_3DXX3_uint8_imgRGB.shape: \", nda_3DXX3_uint8_imgRGB.shape)\n",
    "\n",
    "    #Func_model.predict(np.expand_dims((nda_3DXX3_uint8_imgRGB_disc / 127.5 - 1), axis=0))\n",
    "    nda_3DXX2_probmapDL = Func_model.predict(np.expand_dims((nda_3DXX3_uint8_imgRGB_disc / 127.5 - 1), axis=0))#Estamos dentro de sourcestart, ConfiguracionesTipo2\n",
    "    nda_3DXX2_probmapDL = np.squeeze(nda_3DXX2_probmapDL)\n",
    "\n",
    "    nda_3DXX2_probmapDL_Argmax = np.argmax(nda_3DXX2_probmapDL, axis=2)\n",
    "\n",
    "    plt.imshow(nda_3DXX2_probmapDL_Argmax)\n",
    "    plt.show()\n",
    "    print(\"te predije\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:    \n",
    "    import os\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "\n",
    "    print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "    str_dirModelLoadIn9=r\"20230709_0917_A20220911_class_DeepLabVBS_DatasetEmbrionBa3NC2Tr105Va10Te30Ep29D0_6Mi75_8\"\n",
    "    str_imgRawPathIn9=r\"./COLAB_instance-level-human-parsing2/embryoDataset/video_animal2_proyeccion_SeqDA2/1OR0000.png\"\n",
    "    image = tf.io.read_file(str_imgRawPathIn9)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    image.set_shape([None, None, 3])\n",
    "    #image = tf.image.resize(images=image, size=[1024,1024])#20230610\n",
    "\n",
    "    nda_3DXX3_uint8_imgRGB = image.numpy()\n",
    "    Func_model=tf.keras.models.load_model(r\"saved_models/\"+str_dirModelLoadIn9) #20230119_1734\n",
    "    print(\"basket\")\n",
    "    Func_model.predict(np.expand_dims((nda_3DXX3_uint8_imgRGB / 127.5 - 1), \n",
    "                               axis=0))#Loagregue 20290929\n",
    "    print(\"futbol\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Conda env: deeplabcrf",
   "language": "python",
   "name": "deeplabcrf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
